# 一、JAVA

## 1、生产环境服务器变慢，诊断思路和性能评估

- 整机：top

  top -Hp <pid>显示指定进程ID的所有线程

  系统的负载均衡load average: xx xx xx代表1min 5min 15min（**如果三个值加起来除以3乘以100%，如果高于60%那么是OK的**）

  uptime是top的精简版

- CPU:vmstat

  **vmstat -n x y** 

  procs

    r:运行和等待CPU时间片的进程数，原则上1核CPU的运行队列不要超过2，整个系统的运行队列不能超过总核数的2倍，否则代表系统压力过大

    b:等待资源的进程数，比如正在等待磁盘I/O,网络I/O等。

  cpu

    us:用户进程消耗CPU时间百分比，us值高，用户进程消耗CPU时间多，如果长期大于50%，需优化程序

    sy:内核进程消耗的CPU时间百分比，

    us + sy如果大于80%，说明可能存在CPU不足

    id：处于空闲的CPU百分比

    wa:系统等待IP的CPU时间百分比

    st：来自于一个虚拟机偷取的CPU时间百分比

  

  **mpstat -P ALL 2**	查看所有CPU核信息

  **pidstat -u 1 -p <pid>** 每个进程使用CPU的用量分解信息

- [ ] 内存:free

  应用进程可用内存

  **free |free -g |free -m**

  应用程序可用内存/系统物理内存>70% 内存不足

  应用程序可用内存/系统物理内存<20% 内存不足需要增加内存

  20%<应用程序可用内存/系统物理内存<70% 内存基本够用

  **pidstat -p <pid> -r n(采样间隔秒数)**

- [ ] 硬盘：df

- [ ] 磁盘：iostat

  磁盘I/O性能评估

  **iostat -xdk 2 3**

  rkB/s每秒读取数据量KB

  wkB/s每秒写入数据量KB

  svctm I/O请求的平均服务时间，单位毫秒

  await I/O请求的平均等待时间，单位毫秒

  util 一秒中有百分几的时间用于I/O操作，接近100%时表示带宽跑满，需要优化程序或增加磁盘

  rkB/s wkB/s根据系统应用不同会有不同的值，长期超大数据读写肯定不正常，需要优化程序

  svctm的值与await的值很接近，表示几乎没有I/O等待，磁盘性能好，如果await的值 远高于svctm，则表示I/O队列等待太长，需要程序优化或更换更快磁盘

  **pidstat -d 采样间隔秒数 -p <pid>**

  

- [ ] 网络：ifstat

  ifstat 1

  各网卡的in out

  观察网络负载情况

  程序网络读写是否正常

  程序网络I/O优化

  增加网络I/O带宽

  **流程**

  1、找到占用cpu高的进程，如top

  2、进一步定位，得知后台程序

  jps -l或ps -ef|grep java |grep -v grep (grep -v grep 是过滤掉grep进程)

  3、定位到具体线程或者代码

  ps -mp 进程 -o THREAD,tid,time

  ​	-m显示所有的线程

  ​	-p pid进程使用的cpu时间

  ​	-o 用户自定义格式

  4、将线程ID转为16进制格式

  ​	 printf "%x\n"  <tid>

  5、jstack <pid>|grep <tid> -A60

## 2、OOM问题

​	StackOverFlowError:栈内存满引起

​	OutOfMemoryError:Java heap space		堆内存满

​	OutOfMemoryError:GC overhead limit exceeded 因gc占主要工作时

​	OutOfMemoryError:Direct buffer memory	本地直接内存满时

​	OutOfMemoryError:unable to create new native thread 超出系统可创建线程的最大上限引起

​	OutOfMemoryError:MetaSpace 元空间（本地内存）满引起的

## 3、For循环中++i与i++的区别

```
对于for循环的执行次数上是没有区别的,原因是因为在循环中第三部分的累加永远是在循环体执行后进行操作的
不同点：i++是先引用再++,这样就会针对引用使用临时变量存储，相对++i来说，性能不好。
```

## 4、sychronized原理

```
 ObjectMonitor() {
 	//关键属性
 	_owner        = NULL;//指向持有ObjectMonitor对象的线程
    _WaitSet      = NULL;//存放处于wait状态的线程队列
    _EntryList    = NULL;//存放处于等待锁block状态的线程队列
    _recursions   = 0;//锁重入次数
    _count        = 0;//用来记录该线程获取锁的次数
    //其它属性省略
  }
  
  当多个线程同时访问同步代码时，首先进入_EntryList队列，当某个线程获得到monitor对象时后将_owner对象指向当前线程，同时_count加1，即获得对象锁。
  若持有monitor的线程调用wait()方法后，释放当前持有的monitor对象，_owner置null,_count减1，同时该线程进入_waitSet中等待被唤醒（当前线程执行完毕也进行monitor释放、_owner置null,_count减1）
```

## 5、锁的状态及锁升级过程

```
锁分为：无锁状态、偏向锁、轻量级锁、重量级锁
升级过程：
	1、大多情况下锁不仅不存在多线程竞争，而且总是同一线程多次获得，为了让获得锁的代价更低引入偏向锁
	当一个线程访问同步块并获取锁时，会在对象头中存储偏向的线程ID,之后线程进入和退出同步块时不需要进行CAS操作来加锁与解锁，只需验证对象头里是否存储当前线程的偏向锁，若成功获得了锁，若失败则验证对象头中偏向锁标识是否设置为1，如果没有设置则通过CAS竞争锁，如果设置了则通CAS将对象头偏向锁指向当前线程
	如果出现锁竞争，则暂停持有偏向锁的线程，将对象头中的偏向锁指向的线程ID清空，恢复线程，
	2、轻量级锁
	当访问同步块会在当前线程的栈帧中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，然后线程通过CAS尝试将对象头中的Mark Word指向锁记录的指针，此时有竞争线程进行以上操作时因为之前线程已经更改了，导致当前线程CAS修改失败，同时自锁获锁也失败，此时锁膨胀为重量级锁，线程阻塞，当之前线程释放锁时CAS尝试将Mark Word写会对象头时，此时竞争线程已修改成指向重量级锁的指针，释放锁并唤醒线程，重新争夺锁
```

## 6、TCP三次握手及四次挥手

```
tcp报文中重要字段说明
1、序号(sequence number) 用来标识tcp源端向目的端发送的字节流，发送方对此进行标记
2、确认号(acknowledgement number) 只有ACK标记位为1时，确认序号才有效，Ack = seq + 1
3、标志位(flags) 
	URG:紧急指针有效
	ACK:确认序号有效
	PSH:接收方应尽快将此报文交给应用层
	RST:重置连接
	SYN:发起一个新的连接
	FIN:释放一个连接
note:确认序号acknowledgement number 与ACK标志位不一样，确认方Ack = 发起方Seq + 1
tcp三次握手
	1、初始状态，客户端与服务器均为close状态，且由客户端发起连接，服务器被动接收(listen)
	2、客户端发送标志位SYN=1 seq=x的数据包给服务器，并状态置为SYN-SEND
	3、服务器接收数据包并响应一个SYN=1 ACK=1 seq=y Ack=seq+1的数据包，并状态置为SYN_RCVD
	4、客户收到数据包后并响应ACK=1 seq=x+1 Ack=y+1的数据包，并状态置为ESTABLISHED
	5、服务器接收到客户端数据包后，确认连接，并状态置为ESTABLISHED
note:建立连接中的Ack Seq都是以对方的基础进行计算的，保证了TCP报文的连贯性，只要一方出现报文丢失，就无法成功建立连接。
note:为什么要进行三次握手
	防止服务器开户无效连接增加服务器压力，防止已失效的连接请求报文段引起错误
	如果网络原因导致服务器给客户端的数据报文丢失，客户端会在等待一定超时后关闭连接并重新发起建立连接，
tcp四次挥手
	1、客户端发送FIN=1 seq=u数据包，进入FIN-WAIT-1
	2、服务器接收到后通知应用进程，发送ACK=1 seq=v Ack=u+1 进入CLOSE_WAIT
	3、客户端收到后，进入FIN-WAIT-2状态
	4、服务器应用进程关闭后，会再次发送FIN=1 ACK=1 seq=w Ack=u+1 进入LAST_ACK
	5、客户端收到后返回ACK=1 seq=u+1 Ack=w+1 进入TIME_WAIT状态
	6、服务器接收到后进入关闭状态 客户端等待一段时间后进入关闭状态
note:为什么建立连接需要三次，而释放连接需要四次
	建立连接时，服务器进入握手结段并不需要做任何准备，可以直接返回SYN ACK报文
	释放连接时，因为可能有必要的数据要处理，不能直接关闭，服务器先发送ACK确认，经过CLOSE_WAIT阶段准备后，才返回FIN释放报文
note:为什么客户端需要等2MSL(Maximum Segment Lifetime)才关闭
	为了确认服务器是否收到了自已的ACk确认报文
	如果在2MSL内再次收到了服务器的FIN报文，就说明服务器因为某些原因并没有收到客户端的ACK报文，客户端会重新发出ACK报文，计时器重置
	如果在2MSL内没有再收到服务器的FIN报文，说明服务器收到了客户端的ACK报文，那么就会进入关闭状态
```

## 7、数据库三范式

```
第一范式：强调的是列的原子性，即数据库表的每一列都是不可分开的原子数据项
第二范式：实体属性完全依赖于主关键字
第二范式：任何非主属性不依赖于其它非主属性
```

## 8、JVM的主要组件

```
类加载器、运行时数据区、执行引擎、本地库接口
类加载器将java代码编译成字节码，运行时数据区将字节码加载至内存，字节码文件只是JVM的一套指令集规范，并不能直接交由底层操作系统执行，需要用特殊的字节码解析执行引擎进行解析为系统指令交给CPU执行，过程中需要调用其它语言的本地库接口来实现程序的功能。
```

JVM内存模型：

线程独占->栈（方法栈，线程执行方法时会创建一个栈帧存储局部变量表，操作栈，动态链接，方法出口等信息）、本地方法栈(同方法栈，只是给native类方法使用）、程序计数器（保存当前线程执行的字节码位置，执行native方法时程序计数器为空） 

线程共享->堆（存放对象实例）、方法区（存放已被虚拟机加载的类信息，变量，静态常量）



## 9、面向对象与面向过程的区别

```
面向过程：
	分析解决问题的步骤，通过函数把这些步骤一步步的实现，使用时一一调用即可，性能较高。
面向对象：
	把构成问题的事物分解成各个对象，建立对象的目的并不是为了完成一个个步骤，而是为了描述某个事物在解决整个问题的过程中所发生的行为，面向对象有封装、多态、继承的特性，所以易复用、易维护、易扩展。可以设计出低耦合的系统，但性能上比面向过程要低。
	note:面向对象是以人的认知和思考问题的方式将构成问题的各个方面分解成对象，对象为数据与对数据的操作方法的整体，是对事物抽象后的概念，对同类对象提取出其共性形成类的概念，类通过公共的方法来与外界交互，对象之间通过消息进行通信。
```

## 10、八种基本数据类型、大小、封装类

| 基本类型 | 大小（字节） | 默认值   | 封装类    |
| -------- | ------------ | -------- | --------- |
| char     | 2            | \u0000   | Character |
| byte     | 1            | (byte)0  | Byte      |
| short    | 2            | (short)0 | Short     |
| int      | 4            | 0        | Integer   |
| long     | 8            | 0L       | Long      |
| float    | 4            | 0.0f     | Float     |
| double   | 8            | 0.0d     | Double    |
| boolean  | -            | false    | Boolean   |

注：int自动装箱时，如Integer i = 1;通过编译后，会自动转为Integer i = Integer.valueOf(1); 其它类似

```java
Integer i1 = 100;
Integer i2 = 100;
Integer i3 = 200;
Integer i4 = 200;
System.out.println(i1 == i2);
System.out.println(i3 == i4);
output:true false
分析：
    Integer类中存在IntegerCache内部类，默认缓存范围为 -128~127 此值可通过-XX:AutoBoxCacheMax设置，VM初始化时会将其值赋于java.lang.Integer.IntegerCache.high property
    Integer.valueOf()方法
    public static Integer valueOf(int i) {
        if (i >= IntegerCache.low && i <= IntegerCache.high)
            return IntegerCache.cache[i + (-IntegerCache.low)];
        return new Integer(i);
    }
上例中100在-128~127之间，则返回值为cache中的同一个对象
     200不在-128~127之间，则返回值为new Integer(200),每次都创建一个新的对象。
```

## 11、equals与==的区别

```
==:
	比较的是变量内存中存放的对象的内存地址，即是否指向相同的对象
equals:
	比较的是两个对象的内容是否相等，如果未重写Object中的equals方法，则调用的仍为Object中的
	public boolean equals(Object obj) {
        return (this == obj);
    }
    通过源码可得知Object中的equals方法实现为==
    注：equals方法使用时，将确定不为null的值放在前面，否则一但前面的值为null,则会报NullPointerException
```

```java
    String.class中重写后的equals方法
	public boolean equals(Object anObject) {
        //如果为同一对象则两者内容一定相等
        if (this == anObject) {
            return true;
        }
        //如果指定对象为String类型才有可比性
        if (anObject instanceof String) {
            String anotherString = (String)anObject;
            int n = value.length;
            //如果对象对应的char类型的数组value[]的长度不同则不需要比较，
            if (n == anotherString.value.length) {
                char v1[] = value;
                char v2[] = anotherString.value;
                int i = 0;
                //只有char[] value数组中的每个元素都相同，则认为相等。即比较的为对象的内容
                while (n-- != 0) {
                    if (v1[i] != v2[i])
                        return false;
                    i++;
                }
                return true;
            }
        }
        return false;
    }
```

## 12、Java创建对象的方式

new关键字、反射、clone、序列化

## 13、final的用法

```
1、被final修饰的类不能被继承
2、被final修饰的方法不能被重写，jvm会将其变为内联来提高运行效率
3、被final修饰的变量不可以改变，此变量为引用时，引用指向的内容可变
4、被final修饰的常量在编译阶段会存入变量池中
note:
	对于final域要遵守两个规则
	1、构造函数中对于final域的赋值操作与构造对象的引用不可重排序
	2、初次读取包含final域的引用与初次读取final域的操作不可重排序
```

## 14、线程的基本状态

| 状态名称     | 说明                                                         |
| ------------ | ------------------------------------------------------------ |
| NEW          | 初始状态，线程创建但还未调用start()                          |
| RUNNABLE     | 运行状态，将系统的就绪和运行笼统地称作运行中                 |
| BLOCKED      | 阻塞状态，线程阻塞于锁                                       |
| WAITING      | 等待状态，进入此状态表示线程需要等待其它线程做出一些特定动作 |
| TIME_WAITING | 超时等待状态，不同于WAITING,此状态可以在指定时间后自行恢复   |
| TERMINATED   | 终止状态，表示当前线程已执行完成                             |

## 15、类加载过程及双亲委派模式

### 1、类加载过程

```
加载（文件到内存）-> 利用类的完全限定名查找字节码文件，通过字节码文件创建Class对象
验证（文件格式，元数据，字节码，符号引用）-> 确保字节码文件符合当前虚拟机的要求，不危害虚拟机自身的安全
准备（类变量内存）-> 进行内存分配，为static修饰的变量分配内存并设置初始值，不包含final修饰的静态变量（在编译时分配）
解析（引用替换，字段解析，方法解析，接口解析）-> 将常量池中的符号引用替换为直接引用的过程。
初始化（静态块，静态变量）-> 完成静态代码块的执行和静态变量的赋值。
使用（实例）-> 
卸载（GC）
note:验证、准备、解析三个步骤合称为链接
```

### 2、双亲委派模式

类加载器自顶而下分为Bootstrap ClassLoader、Extension ClassLoader、Application ClassLoader、Custom ClassLoader

双新委派模式即类加载器加载类时先把请求委托至自己的父类加载器执行，依次委派直到顶层的启动类加载器也即Bootstrap ClassLoader

父类加载器能够完成加载则成功返回，否则子类加载器才自己尝试加载

作用：可防止类的重复加载、可防止java核心API被篡改

## 16、Java对象结构

```
对象头：
	1、存储对象自身的运行时数据，如：hashCode,GC分代年龄，锁标识状态，线程持有的锁，偏向线程ID
	2、指向对象的元数据类型，即对象代表哪个类
	若对象为数组，则对象头中还有记录数组长度的部分
实例数据：用来存储对象真正的有效信息，包括从父类继承和自定义的
对齐直译：JVM要求对象的起始地址必须是8字节的整数倍
```

## 17、ThreadPoolExecutor

### 1、线程池的处理流程

![](E:\工作文档\笔记\pictures\ThreadPoolExecutor工作流程图.png)

### 2、构造参数

```java
int corePoolSize,					//核心线程数
int maximumPoolSize,				//最大线程数
long keepAliveTime,					//空闲线程的回收时长
TimeUnit unit,						//keepAliveTime的单位
BlockingQueue<Runnable> workQueue,	//阻塞队列
ThreadFactory threadFactory,		//线程创建工厂
RejectedExecutionHandler handler	//拒绝策略
```

### 3、RejectedExecution Handler

```java
CallerRunsPolicy		//谁调用谁执行
AbortPolicy				//直接中止抛出异常
DiscardPolicy			//丢弃当前的任务
DiscardOldestPolicy		//丢弃队列最早加入的任务
```

### 4、线程池的优势

```
1、降低资源消耗，通过重复使用线程池中已创建的线程减少创建与销毁造成的资源消耗
2、提高响应速度，任务到达可立即执行
3、提高线程的可管理性，线程是稀缺资源，若无限制创建不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以统一的分配，调优和监控
```

## 18、双重校验单例

```java
public class DoubleCheckSingletonDemo {
    private volatile static DoubleCheckSingletonDemo uniqueSingletonInstance;
    private DoubleCheckSingletonDemo() {
    }
    public static DoubleCheckSingletonDemo getInstance() {
        if (uniqueSingletonInstance == null) {
            synchronized (DoubleCheckSingletonDemo.class) {
                if (uniqueSingletonInstance == null) {
                    uniqueSingletonInstance = new DoubleCheckSingletonDemo();
                }
            }
        }
        return uniqueSingletonInstance;
    }
}
note:
	volatile关键字的必要性
    uniqueSingletonInstance = new DoubleCheckSingletonDemo();
	此段代码其实分为三步执行
    	1、为uniqueSingletonInstance分配内存空间
        2、初始化uniqueSingletonInstance
        3、将uniqueSingletonInstance指向分配好的内存地址
    在JVM重排序的情况下，以上步骤可能会变为 1 -> 3 -> 2,单线程情况下不会出现问题，但是多线程的情况下会导致某个线程获得一个还未初始化的实例
   	eg:两个线程t1和t2,t1执行了1、3步骤，这时uniqueSingletonInstance不为null,但却未初始化，此时t2执行时发现uniqueSingletonInstance不为null直接返回，使用时就会出现问题。
    加上volatile后就可以禁止JVM对1、2、3这三个步骤进行重排序可避免以上问题出现。
```

## 19、封装、继承、多态

```
1、封装：就是信息隐藏，利用抽象数据类型将数据及基于数据的操作封装在一起使其构成一个独立实体，隐藏内部细节，通过暴露接口来实现与外界的交互。
2、继承：为了重用父类代码，两个类若存在is-a的关系就可以用继承表示，继承也为多态做了铺垫
3、多态：指程序中定义的引用变量所指向的具体类型及该引用变量发现的方法调用信号在编译期是不确定的，而是在运行期间确定的，不用修改源代码就可以将引用变量绑定到不同的类实现上，从而导致引用变量调用的具体方法随之而改变，让程序可以选择多个运行状态。

多态实现的条件：继承、重写、向上转型
多态实现为分两种：基于继承的实现和基于接口的实现
多态实现机制遵循的原则：当超类对象引用子类对象时，被引用对象的类型决定了具体调的方法，且该方法是在父类中定义过的即被子类重写覆盖的。
```

## 20、JDK动态代理实现

```
JDK动态代理针对实现接口的类生成代理
1、定义实现了InvocationHandler接口的类
2、通过构造函数注入目标类
3、实现invoke方法
4、在主函数中获取目标类的类加载器
5、使用Proxy.newProxyInstance()产生一个代理对象
6、通过代理对象调用目标类的各个方法
```



# 二、gitHub

## 公式

- [ ] ​	关键字 in:name,description,readme
- [ ] ​	关键字 stars:>=5000 查找stars大于等于5000的
- [ ] ​	关键字 forks:>=500 查找forks大于等于500的
- [ ] ​	关键字 forks:100..200 stars 80..100 查找forks在100到200之间并且stars在80到100之间的
- [ ] ​	awesome 关键字	优化查找学习、工具、书籍类相关项目
- [ ] ​	#L10或#L10-#L20 查找对应地址中内容在10到20行的高亮显示
- [ ] ​	location:shanghai language:java 查找指定地方指定语言的gitHub用户

## 命令

1. 查看当前分支最新版本 git rev-parse head | git rev-parse --short head

2. 查看提交日志 git log --graph --all --oneline  eg:graph提交结构 all详细信息 oneline单行显示

3. 强制推送（回退版本使用）git push -f

4. 显示分支 git branch -avv

   ```
   https://github.com/yangerke/monk-series.git
   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
   git clone https://outh2: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@github.com/yangerke/monk-series.git
   ```

5. export LESSCHARSET=utf-8  设置git编码格式

# 三、Nginx

## 1、什么是nginx

​		Nginx是一个高性能的HTTP和反向代理服务器，特点是点用内存少，并发能力强，专为性能优化而开发，有报告表明能支持高达5w个并发连接数。

## 2、相关概念说明

​		正向代理：在客户端配置代理服务来访问目标服务（无代理无法直接访问）。

​		反向代理：客户端是无感的，请求发送到反向代理服务器，由反向代理服务器选择目标服务器获取数据并返回给客户端（反向代理服务器和目标服务器对外就是一个服务器，暴露的是代理服务器地址而隐藏了真实服务器IP地址）。

​		负载均衡：增加服务器数量，将请求分发到各个服务器上，将原先请求集中到单个服务器上的情况改为将请求分发到多个服务器上，将负载分发到不同服务器。

​		动静分离：为了加快网站的解析速度，可以把动态页面和静态页面由不同的服务器来解析，加快解析速度降低原来单个服务器的压力。

## 3、常用操作

​		查看开放端口号 firewall-cmd --list-all

​		设置开发的端口号

​			firewall-cmd -=add-service=http -permanent

​			sudo firewall-cmd --add-port=80/tcp --permanent

​		重启防火墙 firewall-cmd --reload

​		nginx -s reload 重新加载nginx.conf

​		nginx	启动

​		nginx -s stop 关闭

​		

## 4、nginx.conf配置文件组成

- [ ] 全局块

  从配置文件开始到events块之间的内容，主要设置一些影响nginx服务器整体运行的配置命令

  worker_processes 1;值越大，可以支持的并发处理量也越多

- [ ] events块

  events块涉及的指令主要影响Nginx服务器与用户的网络连接

  worker_connections 1024；支持的最大连接数

- [ ] http块

  Nginx服务器配置中最频繁的部分，代理、缓存和日志定义等绝大多数功能和第三方模块的配置

  http块也可以包括http全局块、server块

## 5、配置实例

​		1、打开浏览器，输入www.123.com跳转到linux系统tomcat主页面中

​		2、配置nginx.conf

​			

```java
http {
        include         mime.types;
        default_type    application/octet-stream;
        sendfile        on;
        keepalive_timeout       65;

        server {
                listen          80;
                server_name     192.168.206.128;
                location / {
                        proxy_pass      http://127.0.0.1:8080;
                }
                error_page      500 502 503 504 /50x.html;
        }
}
```



​	实例二	使用nginx反向代理，根据访问路径跳转到不同的端口的服务中

## 6、负载均衡

​		轮询 weight ip_hash fair(服务响应时间最短的)

## 7、原理

主程序Master Process启动后，通过for循环来接收和处理外部信号

主进程通过fork()函数产生worker子进程，每个子进程通过for循环来实现Nginx事件的接收与处理

​	

一个master和多个worker的好处

​		可以使用nginx -s reload热部署，利用nginx进行热部署操作

​		每个worker是独立的进程，如果其中一个worker出现问题，其它worker独立，不会造成服务中断

​	设置多少个worker

​		worker数与服务器cpu数量相同最为合适

​	连接数worker_connections

​		一个请求占用worker多少个连接数，2或4个

​	一个master 四个worker ,一个worker支持最大1024连接数，支持最大并发连接数多少

​		4 * 1024 / 2或4

​		变通的静态访问最大并发数是 worker_connections * worker_processes / 2

​		http反向代理是worker_connections * worker_processes / 4

## 8、Nginx与Apache的区别

| Nginx                      | Apache                               |
| -------------------------- | ------------------------------------ |
| 基于web的服务器            | 基于流程的服务器                     |
| 所有请求由一个线程处理     | 每一个请求产生一个线程               |
| 避免子进程的概念           | 基于子进程                           |
| 偏向速度                   | 偏向功率                             |
| 内存消耗和连接方面好       | 内存消耗和连接方面无提升             |
| 负载匀衡方面较好           | 流量达到进程极限后，将不再建立新连接 |
| 性能和可伸缩性不依赖于硬件 | 依赖于CPU和内存等硬件组件            |



# 四、JUC&JVM

## 	1、Stack栈存储什么

​			8种基本类型的变量、对象的引用变量、实例方法

​			方法放入栈中就叫做栈帧

​			栈帧中主要保存3类数据

​				本地变量：	输入参数和输出参数以及方法内的变量

​				栈操作：记录出栈、入栈的操作

​				栈帧数据：包括类文件、方法等

​			每个方法执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。

# 五、Docker

## 1、容器操作

```
systemctl start docker
systemctl stop docker
从库中查询 docker search XXXX
从库中下载 docker pull 镜像名:tag
查看下载的镜像列表 docker images
删除docker rmi image-id

启动docker run --name XXX -d image-name
eg:docker run --name myredis -d redis
查看列表docker ps(运行中的容器)
docker ps -a 所有的包括之前运行过的
停止docker stop container-name/container-id
启动docker start container-name/container-id
删除docker rm container-id
端口映射-p 6379:6379 
eg:docker run -d -p 6379:6379 --name myredis docker.io/redis
容器日志docker logs container-name/container-id

如果映射端口后访问时报404
docker exec -it 97e2ea91081a /bin/bash
将webapps-dist修改为webapps即可访问 通过输入exit退出当前容器
docker commit -a "作者名字" -m "提交备注信息" 当前要备份的container-id 自定义镜像名:tag

进入容器（如redis：安装了redis的linux小型服务）
docker exec -it container-name bash（注：有此需要修改为 /bin/bash->sh）
查看容器中的IP
docker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' container-name



http://hub-mirror.c.163.com

```

## 2、配置docker阿里云镜像加速pull速度	

```
https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors

sudo mkdir -p /etc/docker
sudo tee /etc/docker/daemon.json <<-'EOF'
{
  "registry-mirrors": ["https://ocxqtviz.mirror.aliyuncs.com"]
}
EOF
sudo systemctl daemon-reload
sudo systemctl restart docker
```

```
连不上docker中的mysql
docker exec -it ecdf3870557e   /bin/bash
mysql -uroot -p123
alter user 'root'@'%' identified by '123' password expire never;
alter user 'root'@'%' identified with mysql_native_password by '1234';
flush privileges;
```

## 3、解决docker容器与系统时间不一致问题

```java
docker cp /etc/localtime 容器ID:/etc/localtime
```



# 六、Spring

## 1、SpringBoot核心组件

```java
//Main方法
//核心注解
@SpringBootApplication
public class NioServerMain {
    public static void main(String[] args) {
        SpringApplication.run(NioServerMain.class, args);
    }
}
```

@SpringBootApplication

```java
@SpringBootConfiguration
@EnableAutoConfiguration
@ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
		@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })
```

@SpringBootConfiguration

```java
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Configuration
public @interface SpringBootConfiguration {

@SpringBootConfiguration继承自@Configuration，二者功能也一致，标注当前类是配置类，
并会将当前类内声明的一个或多个以@Bean注解标记的方法的实例纳入到spring容器中，并且实例名就是方法名。
```

@EnableAutoConfiguration

```java
@Target(ElementType.TYPE)
@Retention(RetentionPolicy.RUNTIME)
@Documented
@Inherited
@AutoConfigurationPackage
@Import(AutoConfigurationImportSelector.class)
public @interface EnableAutoConfiguration {


@AutoConfigurationPackage
以main方法类所在的包进行扫描

@Import(AutoConfigurationImportSelector.class)
AutoConfigurationImportSelector实现了ImportSelector接口
实现了selectorImports()方法，在selectorImports中返回String[]数组，将其中所有的class进行注入
```

## 2、SpringBoo启动过程

```java
1、SpringApplication.run()
2、new SpringApplication()
		//赋值main方法所在类的.class
		this.primarySources = new LinkedHashSet<>(Arrays.asList(primarySources));
		//根据classpath推断应用类型
		this.webApplicationType = WebApplicationType.deduceFromClasspath();
		//加载ApplicationContextInitializer对应的META-INF/spring.factories中的配置信息
		setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class));
		//加载ApplicationListener对应的META-INF/spring.factories中的配置信息
		setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class));
		//根据new RuntimeException().getStackTrace()获取的栈帧信息推断main所在的类名，并通过Class.forName()生成对应的		Class
		this.mainApplicationClass = deduceMainApplicationClass();
3、SpringApplication实例的run()
	StopWatch类是统计执行时长辅助类，非线程安全，只提供开发环境使用
	SpringApplicationRunListener运行时事件监听器 启动初始化的过程中可以根据需求加入自己的逻辑
	根据webApplicationType创建对应的ApplicationContext,此处创建的为AnnotationConfigXXXApplicationContext
	SpringBootExceptionReporter.class对应的META-INF/spring.factories中的配置信息 增加启动异常捕获在catch中
	
	prepareContext()
		applyInitializers(context);//调用ApplicationContextInitializer.initialize()
		listeners.contextPrepared(context);//调用ApplicationContextListener.contextPrePared()
		load(context, sources.toArray(new Object[0]));//加载bean(主要是主方法所属类及部分内部bean)
		listeners.contextLoaded(context);//调用ApplicationContextListener.contextLoaded()
	refreshContext(context);//调用spring refresh()方法
	afterRefresh(context, applicationArguments);
	listeners.started(context);
	
```



## 3、Spring核心逻辑

```java
1、// Prepare this context for refreshing.
    prepareRefresh();
    设置ApplicationContext相关状态，如close active等

2、// Tell the subclass to refresh the internal bean factory.
    //xml形式的bean定义是通过obtainFreshBeanFactory()中xml加载并封装了BeanDefinition
    ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory();
3、// Prepare the bean factory for use in this context.
	//添加ClassLoader、后置处理
	prepareBeanFactory(beanFactory);
4、// Allows post-processing of the bean factory in context subclasses.
	//
	postProcessBeanFactory(beanFactory);
5、// Invoke factory processors registered as beans in the context.
	//执行后置处理操作
	invokeBeanFactoryPostProcessors(beanFactory);
	//其中ConfigurationClassPostProcessor
	//根据main方法启动类进行
			//parser.parse(candidates); ->doProcessConfigurationClass()主要进行类的注解处理
			//parser.validate();
6、// Register bean processors that intercept bean creation.
	//添加BeanPostProcessor 如自定义
	registerBeanPostProcessors(beanFactory);
7、//
```

## NOTE

```
@Conditional
按照特定条件进行Bean注入
自定义实现Conditional接口，实现matches()方法（方法中可根据需求定义相关注入条件）

@ConditionalOnMissingBean
判断是否已经存在指定类的实例，没有则注入，有则不做操作

@ConditionalOnBean
判断是否已存在当前类型实例，如果存在注入，不存在不做操作
```

## 4、SpringMVC处理流程

```java
1、用户请求到DispatcherServlet（doDispatch(HttpServletRequest request, HttpServletResponse response)）
2、根据HandleMapping处理器映射器去查找处理器（HandleExceptionChain）
3、根据HandleExceptionChain获取HandleAdapter处理适配器
4、通过HandleAdapter处理适配器去invoke the handler，并获得ModelAndView
5、调用viewResolver视图解析器对ModelAndView进行解析并得到View
6、对View视图进行渲染并向用户响应结果
```

## 5、注解说明

```
1、数据接收相关
@RequestBody 主要用于处理前端传来的json格式的数据 可标注对象，也可标注单个字段（注：在同一个方法形参列表中只能出现一次）
@RequsetBody和@RequestParam可以同时使用，只是前者接收body中的数据，后者接收url上的key-value
2、@RestController和@Controller的区别
@RestController其实是@ResponseBody与@Controller的组合，但其不能返回页面
@Controller可以返回页面
```



# 七、Redis

## 1、使用Redis约束

```
1、命中率很低
2、写操作很多，频繁需要写入数据库
3、数据大小，如几百兆字节的数据，是否有必要
```

## 2、docker启动redis无redis.conf问题

```
1、创建redis.conf文件在docker容器外
	eg: mkdir docker/redis/conf redis.conf可github下载
	note:如果窗口外安装的有redis可直接使用其redis.conf
2、重新在docker中创建redis容器
	eg:
	docker run 
    -d 
    	--restart always  //docker启动时，本镜像也自动启动
        --privileged=true //容器内的root拥有真正root权限，否则容器内root只是外部普通用户权限
        -p 6379:6379   	  //映射本地端口 6379 至容器端口 6379   
        -v /docker/redis/conf/redis.conf:/etc/redis.conf    //映射配置文件
        -v /docker/redis/data:/data 					   //映射数据目录（docker存在）
        --name redis //新创建
    redis //镜像名称
    redis-server /etc/redis.conf //指定配置文件启动redis-server进程
    --appendonly yes	//开启数据持久化
3、WARNING overcommit_memory is set to 0! Background save may fail under low memory condition.
	echo 1 > /proc/sys/vm/overcommit_memory
```

## 3、常用命令

```
1、docker中查看redis版本
	eg:docker exec -it container_id redis-server -v
2、查看 NetworkSettings 配置中 IPAdress
	eg:docker inspect redis-6379
	eg:docker inspect --format='{{.NetworkSettings.IPAddress}}' redis-6379
3、连接
	redis-cli -h host -p port -a pwd --raw
	--raw 可以格式数据格式
```

## 4、参数说明

```
1、bind 127.0.0.1
	bind选项为空，则允许所有来自可用网络接口的连接
2、protected-mode no
	保护模式，若为yes，只允许本地客户端连接
3、appendonly yes
	开启后，会记录每次写入数据的命令至appendonly.aof文件
```

## 5、redis集群

```
note:本集群环境为docker，使用挂载覆盖方式统一配置
1、联网获取redis.conf配置文件（docker启动无redis.conf配置文件，可以直接容器操作，也可以选择挂载覆盖）
	wget http://download.redis.io/redis-stable/redis.conf
2、修改redis.conf的参数配置
	#bind 127.0.0.1	
	protected-mode no
	appendonly yes 
3、使用挂载覆盖方式启动redis容器
	docker run --name redis6379 -p 6379:6379 -v /docker/redis/conf/redis.conf:/etc/redis.conf -d redis redis-server /etc/redis.conf
4、查看redis6379(master) NetworkSettings 配置中 IPAddress
	docker inspect --format='{{.NetworkSettings.IPAddress}}' redis6379
5、复制出redis.conf重新增加从服务器的配置并进行配置
	# replicaof <master ip> <master port>
	replicaof 172.17.0.2 6379 #Redis主机(Master)IP 端口
6、同样的方式挂载覆盖方式启动相应的从服务器
7、查看信息
	docker exec -it 服务名字 redis-cli info replication
	# Replication
    role:master
    connected_slaves:2
    slave0:ip=172.17.0.3,port=6379,state=online,offset=4521,lag=1
    slave1:ip=172.17.0.4,port=6379,state=online,offset=4521,lag=1
    master_replid:7d31b54b2f9f45056c0b2dc14b9f4625a0cdccd3
    master_replid2:0000000000000000000000000000000000000000
    master_repl_offset:4664
    second_repl_offset:-1
    repl_backlog_active:1
    repl_backlog_size:1048576
    repl_backlog_first_byte_offset:1
    repl_backlog_histlen:4664
8、测试主从读写及同步功能
9、添加sentinel进行高可用配置
	添加sentinel.conf配置文件
	# 主节点信息，格式：sentinel <master-name> <ip> <redis-port> <quorum>；
    # <master-name> 自定义主节点名称；
    # <ip> <redis-port> 主节点的ip和端口；
    # <quorum> 多少个哨兵节点检测到有问题就进行故障转移
    sentinel monitor 监控名字（自定义） 172.17.0.2 6379 1
    port 26379
```

## 6、Redis事务执行流程

![](E:\工作文档\笔记\pictures\redis事务执行流程.png)

1.首先查看对应的端口是否已经开启,以设置的6379端口为例:
firewall-cmd --query-port=6379/tcp

2:没有开启端口的话进行端口的开启,显示success即成功:
firewall-cmd --zone=public --add-port=6379/tcp --permanent

3.没有重启防火墙的时候查询6379端口依然显示没有开启,然后重启防火墙之后显示端口重启成功:
重启防火墙:firewall-cmd --reload

# 八、vi&vim

## 1、vi/vim键盘图

![](E:\工作文档\笔记\pictures\vi-vim-功能图.gif)

# 九、Intellij IDEA->shortcut keys

| 快捷键         | 功能              |
| -------------- | ----------------- |
| ctrl + alt + t | surround with     |
| ctrl + F12     | 列出当类的方法    |
| ctrl + o       | override method   |
| ctrl + i       | implements method |
| alt + 7        | 打开structure     |

# 十、MyBatis

## 1、MyBatis介绍

是一种半ORM对象关系映射框架，内部封闭了JDBC，开发时只需要关注SQL，而不需要处理加载驱动、创建连接、创建Statement等过程，开发者直接编写原生态sql，可严格控制sql执行性能，灵活度高。

## 2、MyBatis优缼点

```
优点：
	1、基于sql编程，灵活，sql写于xml文件解除了与代码的耦合方便统一管理，提供了xml标签支持动态sql
	2、相比JDBC，减少了一半以上的代码量，不需要手动开关连接
	3、很好的与各数据库兼容，因为mybatis是用JDBC来连接数据库的，因此只要数据库支持JDBC，就支持Mybatis
	4、能够与Spring很好的集成
	5、提供了映射标签，支持对象与数据库的ORM字段关系映射
缺点：
	1、sql编写工作量大，当字段多，关联表多时
	2、sql语句依赖于数据库，导致数据库移植性差，不能随便更换数据库
```

# 十一、MySQL

## 序、docker安装mysql

```
1、docker search mysql
2、docker pull mysql:version
3、测试型安装 查看相应配置位置
	安装
	docker run -d -p 3306:3306 --name mysql-service -e MYSQL_ROOT_PASSWORD="root" mysql
	进入docker容器
	docker exec -it mysql-service bash
	确认docker内mysql文件相关路径
	mysql --help | grep my.cnf
4、创建本地路径（非docker容器内）
	mkdir -p /opt/docker/mysql/conf && mkdir -p /opt/docker/mysql/data
5、复制测试容器中的配置文件至本地
	docker cp mysql-test:/etc/mysql/my.cnf /opt/docker/mysql/data
6、删除测试mysql
	docker rm containId
7、重新创建mysql
	docker run --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=root --mount type=bind,src=/opt/docker/mysql/conf/my.cnf,dst=/etc/mysql/my.cnf --mount type=bind,src=/opt/docker/mysql/data,dst=/var/lib/mysql -d mysql
	
	
允许group by 参数非必要只出现在group by后面的字段	
set global sql_mode="STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION";
```



## 1、关联表中条件放在ON后与WHERE的区别

```
注：数据库在连接两张或多张表时会产生临时表，然后将临时表返回
1、ON条件是生成临时表时使用的条件，它不管ON中的条件是否为真，都会返回完整数
2、where条件是在临时表生成好后，再对临时表进行过滤的条件。这时已经没有left join的含义（必须返回左边表的记录）了，条件不为真的就全部过滤掉
```

## 2、SQL SELECT语句执行顺序

```
1、from子句组装来自不同数据源的数据；
2、where子句基于指定的条件对记录行进行筛选；
3、group by子句将数据划分为多个分组；
4、使用聚集函数进行计算；
5、使用having子句筛选分组；
6、计算所有的表达式；
7、select 的字段；
8、使用order by对结果集进行排序。
```

## 3、索引

```
索引是对数据库表中一个或多个列的值进行排序的结构，建立索引有助于快速获取数据
MySql的索引种类：
	主键索引PRIMARY（数据列不允许重复，不允许为null,一张表只能有一个主键索引）
	唯一索引UNIQUE（数据列不允许重复，允许为null,一张表允许多列创建唯一索引）
		alter table table_name add unique (column);
		alter table table_name add unique (column1, column2);
	普通索引INDEX
		alter table table_name add index index_name(column);
		alter table table_name add index index_name(column1, column2);
	全文索引FULLTEXT
		alter table table_name add FULLTEXT(column);
索引并非越多越好，创建索引需要耗费资源：增加了数据库的存储空间，在插入和删除时需要花费较多的时间对索引进行维护
```

## 4、SQL优化

### 1、sql方面

```
1、查询语句避免使用select *
2、减少子查询的使用，使用关联查询替代
3、减少使用in和not in，使用exists和not exists和关联查询语句替换
4、涉及or操作应尽量用union和union all来替换
5、避免在where后使用!=/<>/null值判断,会导致放弃使用索引而扫描全表
```

### 2、大表优化

```
1、限定查询数据的范围，禁止不带任何范围条件的查询
2、读写分离，数据库拆分，主从读写分离
3、垂直分区
	根据数据库表的相关性进行拆分，即数据库表的列拆分，把一张列比较多的表拆分多张表
	优点：使表的列数据变小，在查询时减少读取的block和IO次数。简化表结构易于维护
	缺点：主键出现冗余，需要管理冗余列，增加获取数据的复杂度
4、水平分区
	保持数据表结构不变，通过某种策略存储数据分片，这样每一片数据分散到不同的表或库中，达到分布式的目的，水平拆分可支持非常大的数据量。
	注：分表仅仅是解决了单表数据过大的问题，但表内容还在同一台机器上，对于提升mysql的并发能力没有什么意义，水平拆分最好是分库。但分库又会引来事务问题等，带来逻辑，部署，运维的复杂度。
```

## 5、并发事务问题

```
1、脏读：一个事务读取并修改了数据但还未提交，另一个事务读取到了未提交的数据并以此为操作基础的问题
2、丢失修改：两个事务并发读取了同一份数据，事务1提交了后，事务2也提交，但对于事务1提交的结果进行覆盖导致事务1的操作丢失问题
3、不可重复读：事务1中第一次对数据读取后，事务2读取并修改提交了操作结果，事务1此时重新读取该数据时与第一次读取的不一致问题。
4、幻读：事务1读取了多行数据，但事务2添加或删除了部分数据，事务1重新读取时发现读取结果与第一次的不一致问题。
```

## 6、事务隔离级别

| 隔离级别                 | 脏读 | 不可重复读 | 幻读 |
| ------------------------ | ---- | ---------- | ---- |
| READ-UNCOMMITED 读未提交 | 有   | 有         | 有   |
| READ-COMMITED 读已提交   | 无   | 有         | 有   |
| REPEATABLE-READ 可重复读 | 无   | 无         | 有   |
| SERIALIZABLE 可串行化    | 无   | 无         | 无   |

MySQL InnoDB存储引擎的默认隔离级别为REPEATABLE-READ

## 7、MySQL的数据类型

### 1、整数类型

| 数据类型  | 字节数 |
| --------- | ------ |
| TININT    | 1      |
| SMALLINT  | 2      |
| MEDIUMINT | 3      |
| INT       | 4      |
| BIGINT    | 8      |

长度可提定，如int(11),但这个长度只是显示字符的个数，不限制实际的合法范围

### 2、实数类型

| 数据类型 |                                                |
| -------- | ---------------------------------------------- |
| FLOAT    |                                                |
| DOUBLE   |                                                |
| DECIMAL  | 可以存储比bigint还要大的整型，可存储精确的小数 |

### 3、字符串类型

| 数据类型 |                                                              |
| -------- | ------------------------------------------------------------ |
| VARCHAR  | 存储可变字符串比定长节省空间                                 |
| CHAR     | 定长，根据长度分配足够的空间，适合存储很短的字符串或者所有值都接近同一个长度 |
| TEXT     |                                                              |
| BLOB     |                                                              |

对于经常变更的数据，CHAR比VARCHAR更好，CHAR不容易产生碎片

对于非常短的列，CHAR比VARCHAR在存储空间上更有效率

使用时尽量分配符合需要的最短而合适的空间，过大排序会消耗更大的空间

避免使用TEXT，BLOB类型，查询时会使用临时表，导致严重的性能开销

### 4、枚举ENUM

### 5、日期和时间

​	timestamp 空间效率要高于datetime

## 8、锁

| 存储引擎 | 行锁                                                         | 表锁                                                         |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| MyISAM   | 不支持                                                       | 支持                                                         |
| InnoDB   | 支持                                                         | 支持                                                         |
|          | 行锁特点：开销大，加锁慢；会出现死锁；锁定粒度小，发生锁冲突概率小，并发度高 | 表锁特点：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突概率大，并发度最低 |

### 1、MyISAM表锁

对于MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求，

对于MyISAM表的写操作，会阻塞其他用户对同一表的读和写请求

MyISAM在执行查询语句前会自动给对应表添加读锁，在执行写改删操作前会自动给对应表添加写锁，用户不需要使用LOCK TABLE命令进行显式加锁

并发请求请写锁时，MySQL会优先处理写请求，即便读请求早于写请求进入队列。MyISAM引擎不适合有大量写操作与读操作的原因是大量的写请求会占锁使得读请求很难获得锁而处于阻塞。

```mysql
查询表级锁争用情况
mysql> show status like 'table%';  
+-----------------------+-------+  
| Variable_name         | Value |  
+-----------------------+-------+  
| Table_locks_immediate | 2979  |  
| Table_locks_waited    | 0     |  
+-----------------------+-------+  
2 rows in set (0.00 sec)) 
```



### 2、InnoDB锁问题

InnoDB支持了事务和行锁，但事务也带来了新问题，如数据丢失、脏读、不可重复读、幻读问题，但可通过事务的隔离级别进行控制，事务的隔离级别越高，则代价就越大，它实质上就是将事务“串行化”。

```mysql
查询行锁争用情况
mysql> show status like 'innodb_row_lock%';  
+-------------------------------+-------+  
| Variable_name                 | Value |  
+-------------------------------+-------+  
| InnoDB_row_lock_current_waits | 0     |  
| InnoDB_row_lock_time          | 0     |  
| InnoDB_row_lock_time_avg      | 0     |  
| InnoDB_row_lock_time_max      | 0     |  
| InnoDB_row_lock_waits         | 0     |  
+-------------------------------+-------+  
5 rows in set (0.01 sec)  
如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高
可以通过设置InnoDB Monitors来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。
具体方法如下：  
mysql> CREATE TABLE innodb_monitor(a INT) ENGINE=INNODB;  
Query OK, 0 rows affected (0.14 sec)  
然后就可以用下面的语句来进行查看：  
mysql> Show innodb status\G;  
*************************** 1. row ***************************  
  Type: InnoDB  
  Name:  
Status:  
…  
…  
------------  
TRANSACTIONS  
------------  
Trx id counter 0 117472192  
Purge done for trx's n:o < 0 117472190 undo n:o < 0 0  
History list length 17  
Total number of lock structs in row lock hash table 0  
LIST OF TRANSACTIONS FOR EACH SESSION:  
---TRANSACTION 0 117472185, not started, process no 11052, OS thread id 1158191456  
MySQL thread id 200610, query id 291197 localhost root  
---TRANSACTION 0 117472183, not started, process no 11052, OS thread id 1158723936  
MySQL thread id 199285, query id 291199 localhost root  
Show innodb status  
…  
监视器可以通过发出下列语句来停止查看：  
mysql> DROP TABLE innodb_monitor;  
Query OK, 0 rows affected (0.05 sec)  
```

对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)

对于普通SELECT语句，InnoDB不会加任何锁；事务可以通过以下语句显示给记录集加共享锁或排他锁。

- 共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE。
- 排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE。

InnoDB是通给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则InnoDB将升级为表锁



show processlist;

kill 952235;

## 9、MYSQL函数

1、**ROW_NUMBER() OVER (ORDER BY column DESC)** 

​	从1开始，为每一条分组记录返回一个数字, 先把column列降序，再为降序后每条记录返回一个序号。

2、**ROW_NUMBER() OVER (PARTITION BY column1 ORDER BY column2)** 

 	根据column1分组，在分组内部根据column2排序，为每个分组中的数据生成一个自增序号。

## 10、PLAN

**Explain Plan**

执行计划，包含了一个SELECT(后续版本支持UPDATE等语句)的执行

**主要字段**

**id**

编号，从1开始，执行的时候从大到小，相同编号从上到下依次执行。

**Select_type**

- SIMPLE 简单查询

- PRIMARY 最外层查询

- SUBQUERY 子查询

- DEPENDENT SUBQUERY：  取决于外层查询的子查询

- UNION:  UNION子句右侧的SELECT子句

  

**type**

ALL, index, range, ref, eq_ref, const, system, NULL(从左到右，性能从差到好)

- system表仅有一行(=系统表)。这是const联接类型的一个特例。
- const表最多有一个匹配行，它将在查询开始时被读取。因为仅有一行，在这行的列值可被优化器剩余部分认为是常数。const表很快，因为它们只读取一次！
- eq_ref对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY。
- ref对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取。如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY(换句话说，如果联接不能基于关键字选择单个行的话)，则使用ref。如果使用的键仅仅匹配少量行，该联接类型是不错的。ref可以用于使用=或<=>操作符的带索引的列。ref_or_null该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。
- index_merge该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。
- unique_subquery该类型替换了下面形式的IN子查询的ref：`value IN (SELECT primary_key FROM single_table WHERE some_expr)`。 unique_subquery是一个索引查找函数，可以完全替换子查询，效率更高。index_subquery该联接类型类似于unique_subquery。可以替换IN子查询，但只适合下列形式的子查询中的非唯一索引：`value IN (SELECT key_column FROM single_table WHERE some_expr)`
- range只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。 当使用=、<>、>、>=、<、<=、IS NULL、<=>、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range。
- index该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。 当查询只使用作为单索引一部分的列时，MySQL可以使用该联接类型。
- ALL对于每个来自于先前的表的行组合，进行完整的表扫描。如果表是第一个没标记const的表，这通常不好，并且通常在它情况下很差。通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。

**possible_keys**

可能用到的索引

**key**

使用的索引

**table**

表名

**key_len**

索引的大小（字节数）

```
索引长度的计算公式：

因为联合索引的结构特点， 我们需要确认命中索引 tb_item_title_price_num 是命中了 title 列、price 列，还是 num 列。

想要会分析，就需要掌握索引长度的计算方法了。

1、索引长度公式

所有的索引字段，如果没有设置 not null，则需要加一个字节。

定长字段，int 占四个字节、date 占三个字节、char(n) 占 n 个字符。

对于变成字段 varchar(n)，则有 n 个字符 + 两个字节。

不同的字符集，一个字符占用的字节数不同。latin1 编码的，一个字符占用一个字节，gbk 编码的，一个字符占用两个字节，utf8 编码的，一个字符占用三个字节，utf8mb4 编码的，一个字符占四个字节

索引长度 char()、varchar() 索引长度的计算公式：

Character Set：utf8mb4=4,utf8=3,gbk=2,latin1=1) * 列长度 + 1(允许 null) + 2(变长列)

综上可得：上述 tb_item 表中，使用的 utf8 编码

所以 title 字段的索引长度是 3 * 100 + 0 + 2 = 302

price 字段的索引长度是 8

num 字段的索引长度是 4

tb_item_title_price_num 索引总共长度是 302 + 8 + 4 = 314
```

**ref**

**rows**

可能扫描的行数

**Extra**

其他信息

- Distinct:一旦[MySQL](http://lib.csdn.net/base/mysql)找到了与行相联合匹配的行,就不再搜索了
- Not exists: MYSQL优化了LEFT JOIN,一旦它找到了匹配LEFT JOIN标准的行,就不再搜索了
- Range checked for each Record（index map:#）:没有找到理想的索引,因此对于从前面表中来的每一个行组合,MYSQL检查使用哪个索引,并用它来从表中返回行。这是使用索引的最慢的连接之一
- Using filesort: **看到这个的时候,查询就需要优化了**。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行
- Using index: 列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的,这发生在对表的全部的请求列都是同一个索引的部分的时候
- Using temporary **看到这个的时候,查询需要优化了**。这里,MYSQL需要创建一个临时表来存储结果,这通常发生在对不同的列集进行ORDER BY上,而不是GROUP BY上
- Where used 使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行,并且连接类型ALL或index,这就会发生,或者是查询有问题不同连接类型的解释（按照效率高低的顺序排序



expain出来的信息有10列，分别是id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra,下面对这些字段出现的可能进行解释：

一、 id

我的理解是SQL执行的顺序的标识,SQL从大到小的执行

1. id相同时，执行顺序由上至下

2. 如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行

3.id如果相同，可以认为是一组，从上往下顺序执行；在所有组中，id值越大，优先级越高，越先执行

二、select_type

示查询中每个select子句的类型

(1) SIMPLE(简单SELECT,不使用UNION或子查询等)

(2) PRIMARY(查询中若包含任何复杂的子部分,最外层的select被标记为PRIMARY)

(3) UNION(UNION中的第二个或后面的SELECT语句)

(4) DEPENDENT UNION(UNION中的第二个或后面的SELECT语句，取决于外面的查询)

(5) UNION RESULT(UNION的结果)

(6) SUBQUERY(子查询中的第一个SELECT)

(7) DEPENDENT SUBQUERY(子查询中的第一个SELECT，取决于外面的查询)

(8) DERIVED(派生表的SELECT, FROM子句的子查询)

(9) UNCACHEABLE SUBQUERY(一个子查询的结果不能被缓存，必须重新评估外链接的第一行)



三、table

有可能是

实际的表名如select * from t1;

表的别名 如 select * from t2 as tmp;

derived 如from型子查询时(来自于子查询的派生表)

null 直接计算得结果,不用走表，例如select 1+2

显示这一行的数据是关于哪张表的，有时不是真实的表名字,看到的是derivedx(x是个数字,我的理解是第几步执行的结果)



四、type(重要)

表示MySQL在表中找到所需行的方式，又称“访问类型”。是分析”查数据过程”的重要依据

常用的类型有：ALL, index,  range, ref, eq_ref, const, system, NULL(从左到右，性能从差到好)

ALL：Full Table Scan， MySQL将遍历全表以找到匹配的行 ,逐行做全表扫描.,运气不好扫描到最后一行.  (说明语句写的很失败)

index: Full Index Scan，index与ALL区别为index类型只遍历索引树,相当于data_all index 扫描所有的索引节点,相当于index_all

range:只检索给定范围的行，使用一个索引来选择行,能根据索引做范围的扫描

ref: 表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值,通过索引列,可以直接引用到某些数据行

eq_ref: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件

const、system: 当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。如将主键置于where列表中，MySQL就能将该查询转换为一个常量,system是const类型的特例，当查询的表只有一行的情况下，使用system

NULL: MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。

const、system、NULL指查询优化到常量级别, 甚至不需要查找时间.

五、possible_keys

注意: 系统估计可能用的几个索引,但最终,只能用1个.

指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用

该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。

如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询

六、Key

key列显示MySQL实际决定使用的键(索引)

如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。

七、key_len

表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度(key_len显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据表定义计算而得，不是通过表内检索出的)

不损失精确性的情况下，长度越短越好

八、ref

表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值

九、rows

表示MySQL根据表统计信息及索引选用情况，估算的找到所需的记录所需要读取的行数

有时候结果集中多一列filtered

为什么Mysql explain extended中的filtered列值总是100%执行Mysql的explain extended的输出会比单纯的explain多一列filtered(MySQL5.7缺省就会输出filtered)，它指返回结果的行占需要读到的行(rows列的值)的百分比。按说filtered是个非常有用的值，因为对于join操作，前一个表的结果集大小直接影响了循环的次数。但是我的环境下测试的结果却是，filtered的值一直是100%，也就是说失去了意义。

参考下面mysql5.6的代码，filtered值只对index和all的扫描有效(这可以理解，其它场合，通常rows值就等于估算的结果集大小。)。

十、Extra

性能从好到坏:useing index>usinh where > using temporary | using filesort

该列包含MySQL解决查询的详细信息,有以下几种情况：

Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询

Using filesort：MySQL中无法利用索引完成的排序操作称为“文件排序”

Using where:列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候，表示mysql服务器将在存储引擎检索行后再进行过滤

Using join buffer：改值强调了在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现了这个值，那应该注意，根据查询的具体情况可能需要添加索引来改进能。

Impossible where：这个值强调了where语句会导致没有符合条件的行。

Select tables optimized away：这个值意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行

useing  index代表索引覆盖，就是查询的列正好在索引中，不用回物理行查询数据。参考http://www.cnblogs.com/qlqwjy/p/8593076.html

执行Mysql的explain extended的输出会比单纯的explain多一列filtered(MySQL 5.7缺省就会输出filtered)，它指返回结果的行占需要读到的行(rows列的值)的百分比。按说filtered是个非常有用的值，因为对于join操作，前一个表的结果集大小直接影响了循环的次数。但是我的环境下测试的结果却是，filtered的值一直是100%，也就是说失去了意义。filtered值只对index和all的扫描有效(这可以理解，其它场合，通常rows值就等于估算的结果集大小。)

总结：• EXPLAIN不会告诉你关于触发器、存储过程的信息或用户自定义函数对查询的影响情况

• EXPLAIN不考虑各种Cache

• EXPLAIN不能显示MySQL在执行查询时所作的优化工作

• 部分统计信息是估算的，并非精确值

• EXPALIN只能解释SELECT操作，其他操作要重写为SELECT后查看执行计划。

## 11、EXPLAN

Mysql Explain 详解


一.语法

explain < table_name >

例如: explain select * from t3 where id=3952602;

二.explain输出解释

+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+
| id | select_type | table | type | possible_keys   | key   | key_len | ref  | rows | Extra |
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+

1.id
 我的理解是SQL执行的顺利的标识,SQL从大到小的执行.

例如:
mysql> explain select * from (select * from ( select * from t3 where id=3952602) a) b;
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| id | select_type | table    | type  | possible_keys   | key   | key_len | ref | rows | Extra |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| 1 | PRIMARY   | <derived2> | system | NULL         | NULL  | NULL  | NULL |  1 |    |
| 2 | DERIVED   | <derived3> | system | NULL         | NULL  | NULL  | NULL |  1 |    |
| 3 | DERIVED   | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    |    |  1 |    |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+

很显然这条SQL是从里向外的执行,就是从id=3 向上执行.

\2. select_type

就是select类型,可以有以下几种

(1) SIMPLE
简单SELECT(不使用UNION或子查询等) 例如:
mysql> explain select * from t3 where id=3952602;
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+
| id | select_type | table | type | possible_keys   | key   | key_len | ref  | rows | Extra |
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+
| 1 | SIMPLE    | t3  | const | PRIMARY,idx_t3_id | PRIMARY | 4    | const |  1 |    |
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+

(2). PRIMARY

我的理解是最外层的select.例如:

mysql> explain select * from (select * from t3 where id=3952602) a ;
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| id | select_type | table    | type  | possible_keys   | key   | key_len | ref | rows | Extra |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| 1 | PRIMARY   | <derived2> | system | NULL         | NULL  | NULL  | NULL |  1 |    |
| 2 | DERIVED   | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    |    |  1 |    |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+

(3).UNION

UNION中的第二个或后面的SELECT语句.例如
mysql> explain select * from t3 where id=3952602 union all select * from t3 ;
+----+--------------+------------+-------+-------------------+---------+---------+-------+------+-------+
| id | select_type | table    | type | possible_keys   | key   | key_len | ref  | rows | Extra |
+----+--------------+------------+-------+-------------------+---------+---------+-------+------+-------+
| 1 | PRIMARY    | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    | const |  1 |    |
| 2 | UNION     | t3      | ALL  | NULL         | NULL  | NULL  | NULL | 1000 |    |
|NULL | UNION RESULT | <union1,2> | ALL  | NULL         | NULL  | NULL  | NULL | NULL |    |
+----+--------------+------------+-------+-------------------+---------+---------+-------+------+-------+

(4).DEPENDENT UNION

UNION中的第二个或后面的SELECT语句，取决于外面的查询

mysql> explain select * from t3 where id in (select id from t3 where id=3952602 union all select id from t3) ;
+----+--------------------+------------+--------+-------------------+---------+---------+-------+------+--------------------------+
| id | select_type     | table    | type  | possible_keys   | key   | key_len | ref  | rows | Extra             |
+----+--------------------+------------+--------+-------------------+---------+---------+-------+------+--------------------------+
| 1 | PRIMARY        | t3      | ALL  | NULL         | NULL  | NULL  | NULL | 1000 | Using where         |
| 2 | DEPENDENT SUBQUERY | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    | const |  1 | Using index         |
| 3 | DEPENDENT UNION  | t3      | eq_ref | PRIMARY,idx_t3_id | PRIMARY | 4    | func |  1 | Using where; Using index |
|NULL | UNION RESULT    | <union2,3> | ALL  | NULL         | NULL  | NULL  | NULL | NULL |                 |
+----+--------------------+------------+--------+-------------------+---------+---------+-------+------+--------------------------+

(4).UNION RESULT

UNION的结果。

mysql> explain select * from t3 where id=3952602 union all select * from t3 ;
+----+--------------+------------+-------+-------------------+---------+---------+-------+------+-------+
| id | select_type | table    | type | possible_keys   | key   | key_len | ref  | rows | Extra |
+----+--------------+------------+-------+-------------------+---------+---------+-------+------+-------+
| 1 | PRIMARY    | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    | const |  1 |    |
| 2 | UNION     | t3      | ALL  | NULL         | NULL  | NULL  | NULL | 1000 |    |
|NULL | UNION RESULT | <union1,2> | ALL  | NULL         | NULL  | NULL  | NULL | NULL |    |
+----+--------------+------------+-------+-------------------+---------+---------+-------+------+-------+

(5).SUBQUERY

子查询中的第一个SELECT.

mysql> explain select * from t3 where id = (select id from t3 where id=3952602 ) ;
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------------+
| id | select_type | table | type | possible_keys   | key   | key_len | ref  | rows | Extra    |
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------------+
| 1 | PRIMARY   | t3  | const | PRIMARY,idx_t3_id | PRIMARY | 4    | const |  1 |        |
| 2 | SUBQUERY  | t3  | const | PRIMARY,idx_t3_id | PRIMARY | 4    |    |  1 | Using index |
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------------+

(6). DEPENDENT SUBQUERY

子查询中的第一个SELECT，取决于外面的查询

mysql> explain select id from t3 where id in (select id from t3 where id=3952602 ) ;
+----+--------------------+-------+-------+-------------------+---------+---------+-------+------+--------------------------+
| id | select_type     | table | type | possible_keys   | key   | key_len | ref  | rows | Extra             |
+----+--------------------+-------+-------+-------------------+---------+---------+-------+------+--------------------------+
| 1 | PRIMARY        | t3  | index | NULL         | PRIMARY | 4    | NULL | 1000 | Using where; Using index |
| 2 | DEPENDENT SUBQUERY | t3  | const | PRIMARY,idx_t3_id | PRIMARY | 4    | const |  1 | Using index         |
+----+--------------------+-------+-------+-------------------+---------+---------+-------+------+--------------------------+


(7).DERIVED

派生表的SELECT(FROM子句的子查询)

mysql> explain select * from (select * from t3 where id=3952602) a ;
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| id | select_type | table    | type  | possible_keys   | key   | key_len | ref | rows | Extra |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| 1 | PRIMARY   | <derived2> | system | NULL         | NULL  | NULL  | NULL |  1 |    |
| 2 | DERIVED   | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    |    |  1 |    |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+


3.table

显示这一行的数据是关于哪张表的.
有时不是真实的表名字,看到的是derivedx(x是个数字,我的理解是第几步执行的结果)

mysql> explain select * from (select * from ( select * from t3 where id=3952602) a) b;
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| id | select_type | table    | type  | possible_keys   | key   | key_len | ref | rows | Extra |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| 1 | PRIMARY   | <derived2> | system | NULL         | NULL  | NULL  | NULL |  1 |    |
| 2 | DERIVED   | <derived3> | system | NULL         | NULL  | NULL  | NULL |  1 |    |
| 3 | DERIVED   | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    |    |  1 |    |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+

4.type

这列很重要,显示了连接使用了哪种类别,有无使用索引.
从最好到最差的连接类型为const、eq_reg、ref、range、indexhe和ALL

(1).system

这是const联接类型的一个特例。表仅有一行满足条件.如下(t3表上的id是 primary key)

mysql> explain select * from (select * from t3 where id=3952602) a ;
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| id | select_type | table    | type  | possible_keys   | key   | key_len | ref | rows | Extra |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+
| 1 | PRIMARY   | <derived2> | system | NULL         | NULL  | NULL  | NULL |  1 |    |
| 2 | DERIVED   | t3      | const | PRIMARY,idx_t3_id | PRIMARY | 4    |    |  1 |    |
+----+-------------+------------+--------+-------------------+---------+---------+------+------+-------+

(2).const

表最多有一个匹配行，它将在查询开始时被读取。因为仅有一行，在这行的列值可被优化器剩余部分认为是常数。const表很快，因为它们只读取一次！

const用于用常数值比较PRIMARY KEY或UNIQUE索引的所有部分时。在下面的查询中，tbl_name可以用于const表：
SELECT * from tbl_name WHERE primary_key=1；
SELECT * from tbl_name WHERE primary_key_part1=1和 primary_key_part2=2；

例如:
mysql> explain select * from t3 where id=3952602;
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+
| id | select_type | table | type | possible_keys   | key   | key_len | ref  | rows | Extra |
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+
| 1 | SIMPLE    | t3  | const | PRIMARY,idx_t3_id | PRIMARY | 4    | const |  1 |    |
+----+-------------+-------+-------+-------------------+---------+---------+-------+------+-------+


(3). eq_ref

对于每个来自于前面的表的行组合，从该表中读取一行。这可能是最好的联接类型，除了const类型。它用在一个索引的所有部分被联接使用并且索引是UNIQUE或PRIMARY KEY。

eq_ref可以用于使用= 操作符比较的带索引的列。比较值可以为常量或一个使用在该表前面所读取的表的列的表达式。

在下面的例子中，MySQL可以使用eq_ref联接来处理ref_tables：

SELECT * FROM ref_table,other_table
 WHERE ref_table.key_column=other_table.column;

SELECT * FROM ref_table,other_table
 WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

例如
mysql> create unique index idx_t3_id on t3(id) ;
Query OK, 1000 rows affected (0.03 sec)
Records: 1000 Duplicates: 0 Warnings: 0

mysql> explain select * from t3,t4 where t3.id=t4.accountid;
+----+-------------+-------+--------+-------------------+-----------+---------+----------------------+------+-------+
| id | select_type | table | type  | possible_keys   | key    | key_len | ref            | rows | Extra |
+----+-------------+-------+--------+-------------------+-----------+---------+----------------------+------+-------+
| 1 | SIMPLE    | t4  | ALL  | NULL         | NULL    | NULL  | NULL           | 1000 |    |
| 1 | SIMPLE    | t3  | eq_ref | PRIMARY,idx_t3_id | idx_t3_id | 4    | dbatest.t4.accountid |  1 |    |
+----+-------------+-------+--------+-------------------+-----------+---------+----------------------+------+-------+

(4).ref

对于每个来自于前面的表的行组合，所有有匹配索引值的行将从这张表中读取。如果联接只使用键的最左边的前缀，或如果键不是UNIQUE或PRIMARY KEY（换句话说，如果联接不能基于关键字选择单个行的话），则使用ref。如果使用的键仅仅匹配少量行，该联接类型是不错的。

ref可以用于使用=或<=>操作符的带索引的列。

在下面的例子中，MySQL可以使用ref联接来处理ref_tables：

SELECT * FROM ref_table WHERE key_column=expr;

SELECT * FROM ref_table,other_table
 WHERE ref_table.key_column=other_table.column;

SELECT * FROM ref_table,other_table
 WHERE ref_table.key_column_part1=other_table.column
  AND ref_table.key_column_part2=1;

例如:

mysql> drop index idx_t3_id on t3;
Query OK, 1000 rows affected (0.03 sec)
Records: 1000 Duplicates: 0 Warnings: 0

mysql> create index idx_t3_id on t3(id) ;
Query OK, 1000 rows affected (0.04 sec)
Records: 1000 Duplicates: 0 Warnings: 0

mysql> explain select * from t3,t4 where t3.id=t4.accountid;
+----+-------------+-------+------+-------------------+-----------+---------+----------------------+------+-------+
| id | select_type | table | type | possible_keys   | key    | key_len | ref            | rows | Extra |
+----+-------------+-------+------+-------------------+-----------+---------+----------------------+------+-------+
| 1 | SIMPLE    | t4  | ALL | NULL         | NULL    | NULL  | NULL           | 1000 |    |
| 1 | SIMPLE    | t3  | ref | PRIMARY,idx_t3_id | idx_t3_id | 4    | dbatest.t4.accountid |  1 |    |
+----+-------------+-------+------+-------------------+-----------+---------+----------------------+------+-------+
2 rows in set (0.00 sec)

(5). ref_or_null

该联接类型如同ref，但是添加了MySQL可以专门搜索包含NULL值的行。在解决子查询中经常使用该联接类型的优化。

在下面的例子中，MySQL可以使用ref_or_null联接来处理ref_tables：

SELECT * FROM ref_table
WHERE key_column=expr OR key_column IS NULL;

(6). index_merge

该联接类型表示使用了索引合并优化方法。在这种情况下，key列包含了使用的索引的清单，key_len包含了使用的索引的最长的关键元素。

例如:
mysql> explain select * from t4 where id=3952602 or accountid=31754306 ;
+----+-------------+-------+-------------+----------------------------+----------------------------+---------+------+------+------------------------------------------------------+
| id | select_type | table | type     | possible_keys         | key                | key_len | ref | rows | Extra                                |
+----+-------------+-------+-------------+----------------------------+----------------------------+---------+------+------+------------------------------------------------------+
| 1 | SIMPLE    | t4  | index_merge | idx_t4_id,idx_t4_accountid | idx_t4_id,idx_t4_accountid | 4,4   | NULL |  2 | Using union(idx_t4_id,idx_t4_accountid); Using where |
+----+-------------+-------+-------------+----------------------------+----------------------------+---------+------+------+------------------------------------------------------+
1 row in set (0.00 sec)

(7). unique_subquery

该类型替换了下面形式的IN子查询的ref：

value IN (SELECT primary_key FROM single_table WHERE some_expr)
unique_subquery是一个索引查找函数，可以完全替换子查询，效率更高。

(8).index_subquery

该联接类型类似于unique_subquery。可以替换IN子查询，但只适合下列形式的子查询中的非唯一索引：

value IN (SELECT key_column FROM single_table WHERE some_expr)

(9).range

只检索给定范围的行，使用一个索引来选择行。key列显示使用了哪个索引。key_len包含所使用索引的最长关键元素。在该类型中ref列为NULL。

当使用=、<>、>、>=、<、<=、IS NULL、<=>、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range

mysql> explain select * from t3 where id=3952602 or id=3952603 ;
+----+-------------+-------+-------+-------------------+-----------+---------+------+------+-------------+
| id | select_type | table | type | possible_keys   | key    | key_len | ref | rows | Extra    |
+----+-------------+-------+-------+-------------------+-----------+---------+------+------+-------------+
| 1 | SIMPLE    | t3  | range | PRIMARY,idx_t3_id | idx_t3_id | 4    | NULL |  2 | Using where |
+----+-------------+-------+-------+-------------------+-----------+---------+------+------+-------------+
1 row in set (0.02 sec)

(10).index

该联接类型与ALL相同，除了只有索引树被扫描。这通常比ALL快，因为索引文件通常比数据文件小。

当查询只使用作为单索引一部分的列时，MySQL可以使用该联接类型。

(11). ALL

对于每个来自于先前的表的行组合，进行完整的表扫描。如果表是第一个没标记const的表，这通常不好，并且通常在它情况下很差。通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出。


5.possible_keys

possible_keys列指出MySQL能使用哪个索引在该表中找到行。注意，该列完全独立于EXPLAIN输出所示的表的次序。这意味着在possible_keys中的某些键实际上不能按生成的表次序使用。

如果该列是NULL，则没有相关的索引。在这种情况下，可以通过检查WHERE子句看是否它引用某些列或适合索引的列来提高你的查询性能。如果是这样，创造一个适当的索引并且再次用EXPLAIN检查查询

\6. key

key列显示MySQL实际决定使用的键（索引）。如果没有选择索引，键是NULL。要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。

7.key_len

key_len列显示MySQL决定使用的键长度。如果键是NULL，则长度为NULL。
使用的索引的长度。在不损失精确性的情况下，长度越短越好

\8. ref

ref列显示使用哪个列或常数与key一起从表中选择行。

\9. rows

rows列显示MySQL认为它执行查询时必须检查的行数。

\10. Extra

该列包含MySQL解决查询的详细信息,下面详细.

(1).Distinct
一旦MYSQL找到了与行相联合匹配的行，就不再搜索了

(2).Not exists
MYSQL优化了LEFT JOIN，一旦它找到了匹配LEFT JOIN标准的行，

就不再搜索了

(3).Range checked for each

Record（index map:#）
没有找到理想的索引，因此对于从前面表中来的每一个行组合，MYSQL检查使用哪个索引，并用它来从表中返回行。这是使用索引的最慢的连接之一

(4).Using filesort
看到这个的时候，查询就需要优化了。MYSQL需要进行额外的步骤来发现如何对返回的行排序。它根据连接类型以及存储排序键值和匹配条件的全部行的行指针来排序全部行

(5).Using index
列数据是从仅仅使用了索引中的信息而没有读取实际的行动的表返回的，这发生在对表的全部的请求列都是同一个索引的部分的时候

(6).Using temporary
看到这个的时候，查询需要优化了。这里，MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上，而不是GROUP BY上

(7).Using where
使用了WHERE从句来限制哪些行将与下一张表匹配或者是返回给用户。如果不想返回表中的全部行，并且连接类型ALL或index，这就会发生，或者是查询有问题

# 十二、微服务

## 1、什么是微服务

微服务是一种架构模式或者说一种架构风格，提倡将单一应用程序划分为一组小的服务，每个服务运行在独立的进程中，服务间相互协调相互配合，服务之间采用轻量级的通信机制互相沟通（RESTful API）。

## 2、服务熔断|服务降级

熔断机制是一种应对雪崩效应的微服务链路保护机制。

​	当某个微服务不可用或响应时长过长时，会进行服务降级进而熔断该服务节点的调用，快速响应错误信息。

​	当检测到该节点微服务调用响应正常后恢复调用链路。SpringCloud中的熔断机制是通过Hystrix实现的，Hystrix可监控微服间的调用状况，当失败的调用达到一定的阈值（默认5秒内调用20次）如果失败就启动熔断机制。

服务降级一般是从整体负荷考虑的。服务熔断后，服务不可用，客户端要自己准备一个本地的fallback回调，返回一个缺省值。

## 3、RPC的实现原理

```
1、需要有处理网络连接通讯的模块，负责连接的建立、管理和消息的传输
2、需要有编解码的模块，因为网络通讯传输的是字节码，通过编解码模块进行序列和反序列操作
3、客户端与服务端的支持，服务端提供服务接口并暴露给客户端，客户端调用服务接口的代理实现，代理实现负责收集数据，编码并传输给服务器并等待结果返回。
```

## 4、微服务技术

| 技术         | 落地                                                         |
| ------------ | ------------------------------------------------------------ |
| 服务注册中心 | Eureka(停更)\|Zookeeper\|Consul\|Nacos(推荐)                 |
| 服务调用     | Ribbon(停更不停用)->LoadBalancer(萌芽期)\|Feign(停更)->OpenFeign |
| 服务降级     | Hystrix(停更)-resilience4j(国外推荐)\|sentienl(alibaba国内使用) |
| 服务网关     | Zuul(停更)->Zuul2(未公开，不一定完成)\|gateway               |
| 服务配置     | Config(停更)\|Nacos（推荐）                                  |
| 服务总线     | Bus(停更)\|Nacos(推荐)                                       |



# 十三、Zookeeper

## 1、Zookeeper概念

Zookeeper是一个开发源码的分布式协调服务，它是集群的管理者，监视着集群中各个节点的状态并根据节点提交的反馈进行下步合理的操作，最终将简单易用的接口和性能高效，功能稳定的系统提供于用户。

读请求会被集群中的任意一台机器处理，而写请求会同时发给其他Zookeeper机器并达成一致后，请求才返回成功，因此随着集群机器增多，读请求的吞吐会提高而写请求的会下降。

Zookeeper一个重要的特性是有序性，所有的更新都是全局有序的，每个更新都会有一个唯一的时间戮（zxid，Zookeeper Transaction ID）,读请求只会相对更新有序，读请求返回结果中会带有最新的zxid

## 2、四种类型的数据节点Znode

```
1、持久节点：除非手动删除，否则节点一直存在于机器上
2、临时节点：其生命周期与客户端会话绑定，一旦客户端会话失效，那此客户端创建的所有临时节点都会被移除
3、持久顺序节点：同持久节点，只是增加了顺序性，节点名后会追加一个由父节点维护的自增整型数字
4、临时顺序节点：同临时节点，只是增加了顺序性，节点名后会追加一个由父节点维护的自增整型数字
```

## 3、Server四种工作状态

```
1、LOOKING		寻找Leader状态，此状态则认为没有Leader,需要进入Leader选举状态	
2、FOLLOWING		跟随者状态
3、LEADING		领导者状态
4、OBSERVING		观察者状态
```

# 十四、算法

## 1、排序

排序的稳定性是指排序过程中原数据中相同的元素是否出现位置前后变更

​		<img src="E:\工作文档\笔记\pictures\排序_总结.png"  />

### 1、插入排序

```
在已排序的元素中从后向前扫描，打到合适的位置后插入。
平均与最差时间复杂度为O(n^2)，最好情况(排序前已为有序状态，只是调整排序方式)为O(n)
没有利用新的内存空间，空间复杂度为O(1)
```

<img src="E:\工作文档\笔记\pictures\排序_直接插入排序.gif"  />

### 2、希尔排序		

```
希尔排序是插入排序的升级版，把数组中的数据分成不同的“组”，只有同组中的元素才能进行比较与排序，随着排序进行，“组”会变的越来越少，组中元素也会越来越多，数组整体上会慢慢有序。

```

![](E:\工作文档\笔记\pictures\排序_希尔排序.png)

### 3、选择排序

```
选择排序即每一次都从未排序的元素中查找最小的元素然后放在最前端（已排序的最后位置）。
平均 最坏 最好情况的时间复杂度都为O(n^2),所以时间复杂度上稳定
```

![](E:\工作文档\笔记\pictures\排序_简单选择排序.gif)

### 4、堆排序

```
堆排序是利用了最大堆这种数据结构的排序方式，每次将堆调整为最大堆后，根节点一定是堆中最大的元素，通过取出最大堆的根节点和重新调整堆为最大堆，这样就可以有序的依次取出数组中从大到小有序的结果集
平均 最坏 最好情况的时间复杂度都为O(nlogn)
```

![](E:\工作文档\笔记\pictures\排序_堆排序.gif)

### 5、冒泡排序

```
冒泡排序通过元素的两两交换将队列中最大的元素移动到队列的末尾。
平均 最坏时间复杂度为O(n^2) 最好为O(n)
```

![](E:\工作文档\笔记\pictures\排序_冒泡排序.gif)

### 6、快速排序

```
快速排序是通过一次排序将特排序的数组分为独立的两部分，前半部分都比中间的元素小，后半部分都比中间的元素大，从而确定了中间关键元素的位置。
平均 最好情况时间复杂度都为O(nlogn) 最坏O(n^2)
快速排序的实现依赖的是递归加二分法，但这个二分法并不是完美的二分法。如果二分法每次正好只分到一边，那么一共就有 n-1 层，所以时间复杂度是 n2；其他情况下一共有logn 层，所以时间复杂度是 n*logn。
```

![](E:\工作文档\笔记\pictures\排序_快速排序.gif)

### 7、归并排序

```
归并排序以需要额外空间作为代价，表现比简单选择排序好得多。二路归并排序就是两两排序，然后两个区域一起排序，以此类推
任何情况下 T(n) = O(nlogn)。归并排序主要是靠递归加二分法，每一层的时间代价都是 n 相关，一共有 logn 层，所以时间复杂度是 n*logn。所以无论数组是不是有序的，都会被二分法分为前后两个部分，然后递归下去。
```

![](E:\工作文档\笔记\pictures\排序_归并排序.gif)

### 8、基数排序

```
基数排序是非比较排序。主要思想是对数组中所有元素先根据其个位进行排序，再根据其十位进行排序，之后是百位、千位，以此类推，直到最高位。
任何情况下 T(n) = O(n * k)，其中 k 是桶的个数。
```

![](E:\工作文档\笔记\pictures\排序_基数排序.gif)

### 9、计数排序

```
计数排序是非比较排序。它的核心是将数组中的元素值转换为键存储在额外空间中。主要思想是额外创建一个数组，额外数组中元素下标是待排序数组中元素的值，而额外数组中的值是其下标的值在待排序数组中作为元素的值出现的次数。
计数排序是稳定的。因为它是非比较排序，元素之间的顺序不依赖元素之间的比较。
任何情况下 T(n) = O(n+k)，其中 k 是桶的个数。
```

![](E:\工作文档\笔记\pictures\排序_计数排序.gif)

### 10、桶排序

```
桶排序是计数排序的升级版，也是非比较排序。主要思想是对数组中数值范围进行划分，数组中的每个元素根据其数值的所在范围，进入不同的“桶”。然后在不同的桶中分别对这些元素进行排序（直接插入排序），再依次输出。
桶排序是稳定的。因为它是非比较排序，元素之间的顺序不依赖元素之间的比较。
最好和平均情况下 T(n) = O(n+k)，最差情况下 T(n) = O(n2)，其中 k 是桶的个数。
```

![](E:\工作文档\笔记\pictures\排序_桶排序.gif)

### 代码实现

```java
import java.util.ArrayList;
import java.util.Arrays;

public class Sort {
    public static void main(String[] args) {
        int[] arr = new int[20];
        int index = 0;
        for(int i = 20;i > 0;i--)
            arr[index++] = i;
        System.out.println("原数组：");
        System.out.println(Arrays.toString(arr));
        System.out.println("开始排序");
        arr = MergeSort(arr);
        System.out.println("排序后为：");
        System.out.println(Arrays.toString(arr));
    }

    // 工具：交换数组中元素的位置
    public static int[] swap(int[] arr, int i, int j){
        int temp = arr[i];
        arr[i] = arr[j];
        arr[j] = temp;
        return arr;
    }

    // ****** 1.直接插入排序 ******
    public static int[] InsertionSort(int[] arr){
        if(arr.length == 0 || arr.length == 1)
            return arr;
        for(int i = 0;i < arr.length - 1;i++){
            // 将 i+1 位置的数插入 0 到 i 之间的数组，从后往前遍历
            // current 指 i+1 的位置元素，pre 指 0 到 i 中依次向前遍历的指针
            int current = arr[i+1];
            int pre = i;
            while(pre >= 0 && current < arr[pre]){
                arr[pre+1] = arr[pre];
                pre--;
            }
            // 最后将原来 i+1 位置的元素放入现在 0 到 i+1 之间数组中正确的位置上
            // pre+1 是因为刚才循环结束时又自减了一次
            arr[pre+1] = current;
            // 打印这一轮的排序结果
            System.out.println(Arrays.toString(arr));
        }
        return arr;
    }

    // ****** 2.希尔排序 ******
    // 希尔排序最重要的变量就是 gap，所有需要+1或者自加1的地方都要注意
    public static int[] ShellSort(int[] arr){
        if(arr.length == 0 || arr.length == 1)
            return arr;
        int current, gap = arr.length / 2;
        while(gap > 0){
            for(int  i = gap;i < arr.length;i++){
                // 将 pre+gap 位置的数插入 0 到 pre 之间“同组”的数组，从后往前遍历
                // current 指 pre+gap 的位置元素
                current = arr[i];
                int pre = i - gap;
                while(pre >= 0 && arr[pre] > current){
                    arr[pre+gap] = arr[pre];
                    pre -= gap;
                }
                arr[pre+gap] = current;
                // 打印这一轮的排序结果
                System.out.println(Arrays.toString(arr));
            }
            gap /= 2;
        }
        return arr;
    }

    // ****** 3.简单选择排序 ******
    public static int[] SelectionSort(int[] arr){
        if(arr.length == 0 || arr.length == 1)
            return arr;
        for(int i = 0;i < arr.length - 1;i++){
            // 每一轮挑出一个最小的元素，依次与不断增长的 i 位置的元素交换
            int MinIndex = i;
            for(int j = i;j < arr.length;j++){
                if(arr[j] < arr[MinIndex])
                    MinIndex = j;
            }
            arr = swap(arr,MinIndex,i);
            // 打印这一轮的排序结果
            System.out.println(Arrays.toString(arr));
        }
        return arr;
    }

    // ****** 4.堆排序 ******
    // 主函数
    public static int[] HeapSort(int[] arr){
        if(arr.length == 0 || arr.length == 1)
            return arr;
        int len = arr.length;
        // 堆排序第一步是先把当前数组变成一个最大堆
        arr = AdjustMaxHeap(arr, len-1);
        while(len > 0){
            // 取出堆顶的元素（最大元素）与末尾还没有确定位置的元素交换
            arr = swap(arr,0,len - 1);
            // 打印这一轮的排序结果
            System.out.println(Arrays.toString(arr));
            len--;
            arr = AdjustMaxHeap(arr,len - 1);
            }
        return arr;
    }
    // 调整为最大堆
    public static int[] AdjustMaxHeap(int[] arr, int lastIndex){
        for(int i = (lastIndex - 1) / 2;i>=0;i--){
            arr = AdjustLocalHeap(arr,lastIndex,i);
        }
        return arr;
    }
    //调整局部堆使其成为局部最大堆
    /*
     注意事项：堆中结点是从 1 开始的，但把数组看作堆的话，数组的下标是从 0 开始的
     那么父结点与子结点的关系就会发生变化：
        父结点 = （子结点-1）/2
        左子结点 = 父结点*2+1
        右子结点 = 父结点*2+2
     */
    public static int[] AdjustLocalHeap(int[] arr,int lastIndex,int i){
        // 找出当前结点和左右子结点（如果有左右子结点的话）中最大的元素，让这个最大的元素成为父结点
        int maxIndex = i;
        if(i*2+1 <= lastIndex && arr[i] < arr[i*2+1])
            maxIndex = i*2+1;
        // 这里要多一个右子结点是否大于左子结点的判定
        if(i*2+2 <= lastIndex && arr[i] < arr[i*2+2] && arr[i*2+1] < arr[i*2+2])
            maxIndex = i*2+2;
        // 如果父结点不是三个结点中的最大结点，那么将最大结点变成父结点
        // 再通过递归看看这个比较小的父结点能不能再“往下沉”
        if(maxIndex != i){
            arr = swap(arr,maxIndex,i);
            arr = AdjustLocalHeap(arr,lastIndex,maxIndex);
        }
        return arr;
    }

    // ****** 5.冒泡排序 ******
    public static int[] BubbleSort(int[] arr){
        if(arr.length == 0 || arr.length ==1)
            return arr;
        for(int i = arr.length-1;i > 0;i--){
            for(int j = 1;j <= i;j++){
                if(arr[j] < arr[j-1])
                    arr = swap(arr,j,j-1);
            }
            // 打印这一轮的排序结果
            System.out.println(Arrays.toString(arr));
        }
        return arr;
    }

    // ****** 6.快速排序 ******
    //主函数
    public static int[] QuickSort(int[] arr){
        if(arr.length == 0 || arr.length ==1)
            return arr;
        arr = LocalQuickSort(arr,0,arr.length -1 );
        return arr;
    }
    // 快速排序
    public static int[] LocalQuickSort(int[] arr, int start, int last){
        if(start >= last)
            return arr;
        // benchmark 指基准数，也就是这一轮将要确定位置的数
        int benchmark = arr[start];
        int left = start;
        int right = last;
        while(left < right){
            // 必须右指针先走
            while(arr[right] > benchmark && left < right) right--;
            if(arr[right] <= benchmark && left < right) arr[left++] = arr[right];
            while(arr[left] < benchmark && left < right) left++;
            if(arr[left] >= benchmark && left < right) arr[right--] = arr[left];
        }
        arr[left] = benchmark;
        // 打印这一轮的排序结果
        System.out.println(Arrays.toString(arr));
        // 通过递归，分别对已确定位置的数的两边区域进行快速排序
        arr = LocalQuickSort(arr,start,left-1);
        arr = LocalQuickSort(arr,left+1,last);

        return arr;
    }

    // ****** 7.归并排序 ******
    // 主函数
    public static int[] MergeSort(int[] arr){
        if(arr.length == 0 || arr.length ==1)
            return arr;
        arr = Merge(arr,0,arr.length-1);
        return arr;
    }
    // 归并排序
    public static int[] Merge(int[] arr,int start,int last){
        // start < last 的判断意味着 arr 指定的范围内必须至少有两个元素
        if(start < last){
            int mid = (start + last) / 2;
            // 左右部分分别递归
            arr = Merge(arr,start,mid);
            arr = Merge(arr,mid+1,last);
            // 递归层面：从里往外依次将左半部分和右半部分整合成一个部分
            arr = merge(arr,start,mid,last);
        }
        return arr;
    }
    public static int[] merge(int[] arr,int start,int mid,int last){
        // tempArr 指一个额外数组，用来临时给 arr 中同一区域的元素排序
        int[] tempArr = new int[arr.length];
        // p1 指 arr 指定区域的左半部分的指针，p2 指 arr 指定区域的右半部分的指针，p 指额外数组 tempArr 的指针
        int p1 = start, p2 = mid+1, p = start;
        // 从指定区域的左右半部分中取出最小元素放入额外数组，完成指定区域内的排序
        while(p1 <= mid && p2 <= last){
            if(arr[p1] <= arr[p2])
                tempArr[p++] = arr[p1++];
            else
                tempArr[p++] = arr[p2++];
        }
        while(p1 <= mid) tempArr[p++] = arr[p1++];
        while(p2 <= last) tempArr[p++] = arr[p2++];
        // 将额外数组中的数据覆盖到原 arr 数组中
        for(int i = start;i <= last;i++)
            arr[i] = tempArr[i];
        System.out.println(Arrays.toString(arr));
        return arr;
    }

    // ****** 8.基数排序 ******
    public static int[] RadixSort(int[] arr){
        if(arr.length == 0 || arr.length ==1)
            return arr;
        // max 指数组中最大的数，maxDigit 指这个最大的数是几位数
        int max = arr[0];
        for(int x:arr)
            max = Math.max(x,max);
        int maxDigit = 0;
        while(max != 0){
            max /= 10;
            maxDigit++;
        }
        // mod 用于为数组中的数取余数，div 用于把通过 mod 取的余数变成个位数
        int mod = 10;
        int div = 1;
        ArrayList<ArrayList<Integer>> bucket = new ArrayList<ArrayList<Integer>>();
        for(int j = 0;j < 10;j++){
            bucket.add(new ArrayList<Integer>());
        }
        for(int i = 0;i<maxDigit;i++,mod *= 10,div *= 10){
            // 打印这一轮的排序结果
            System.out.println(Arrays.toString(arr));
            for(int j = 0;j < arr.length;j++){
                // num 指当前元素 arr[j] 的个/十/百/千位是几
                int num = (arr[j] % mod) / div;
                bucket.get(num).add(arr[j]);
            }
            int index = 0;
            for(int j = 0;j < 10;j++){
                if(bucket.get(j).size() != 0){
                    for(int x:bucket.get(j))
                        arr[index++] = x;
                    // 将桶中所有的动态数组清空，否则第二次循环开始再用到这些动态数组时里面还会有数据
                    bucket.get(j).clear();
                }
            }
        }
        return arr;
    }

    // ****** 9.计数排序 ******
    public static int[] CountingSort(int[] arr){
        if(arr.length ==0 || arr.length == 1)
            return arr;
        int min, max;
        min = max = arr[0];
        for(int x: arr){
            if(x > max)
                max = x;
            if(x < min)
                min = x;
        }
        // bucket 指用来存储每个元素出现次数的桶，长度为元素的范围
        int[] bucket = new int[max - min +1];
        // 把 bucket 用 0 填满，因为之后要累加
        Arrays.fill(bucket,0);
        // 在 bucket 中相应的位置记录每个元素出现的次数
        for(int x:arr){
            bucket[x - min]++;
        }
        int index = 0;
        // 依次从 bucket 中提取元素覆盖到原来的 arr 上
        for(int i =0;i<bucket.length;i++){
            while(bucket[i] != 0){
                arr[index++] = i + min;
                bucket[i]--;
            }
        }
        return arr;
    }

    // ****** 10.桶排序 ******
    // 主函数
    public static int[] BucketSort(int[] arr){
        if(arr.length == 0 || arr.length == 1)
            return arr;
        arr = Bucket(arr,5);
        return  arr;
    }
    // 桶排序
    // bucketSize 指每个桶的容量，bucketCount 指桶的个数
    public static int[] Bucket(int[] arr,int bucketSize){
        int min,max;
        min = max = arr[0];
        for(int x:arr){
            if(x > max)
                max = x;
            if(x > min)
                min = x;
        }
        int bucketCount = (max - min) / bucketSize +1;
        ArrayList<ArrayList<Integer>> bucket = new ArrayList<ArrayList<Integer>>();
        for(int i = 0;i < bucketCount;i++)
            bucket.add(new ArrayList<Integer>());
        for(int x: arr){
            // 遍历每个桶
            for(int bucketIndex = 0;bucketIndex < bucketCount;bucketIndex++){
                // 如果 arr 当前元素在该桶的范围内，则将该元素放入该桶内，并结束遍历每个桶的循环
                if(x >= min + bucketIndex*bucketSize && x < min + (bucketIndex+1)*bucketSize){
                    bucket.get(bucketIndex).add(x);
                    break;
                }
            }
        }
        int index = 0;
        for(int i = 0;i < bucketCount;i++){
            // 对每个桶使用直接插入排序，调整桶内元素的顺序
            bucket.set(i,InsertionSortOfArrayList(bucket.get(i)));
            for(int x:bucket.get(i))
                arr[index++] = x;
        }
        return arr;
    }
    // 针对动态数组的直接插入排序
    public static ArrayList<Integer> InsertionSortOfArrayList(ArrayList<Integer> arr){
        if(arr.size() == 0 || arr.size() ==1)
            return arr;
        int current;
        int pre;
        for(int i = 0;i < arr.size() - 1;i++){
            pre = i;
            current = arr.get(i+1);
            while(arr.get(pre) > current && pre >= 0){
                arr.set(pre+1,arr.get(pre));
                pre--;
            }
            arr.set(pre+1,current);
        }
        return arr;
    }
}
```

# 十五、Netty

## 1、IO模型

### 1、概念说明

```
a) 用户空间与内核空间
	操作系统都采用的虚拟存储器，内核独立于普通应用程序，可以访问受保护的内存空间和底层硬件设备的权限。为了保护用户进程不能直接操作内核保护其安全，操作系统将虚拟空间分为内核空间和用户空间。
b) 进程切换
	为了控制进程的执行，内核必须有能力挂起正在CPU上运行的进程，并恢复以前挂起的某个进程的执行，即进程切换。
	进程间的切换工作有很复杂的操作流程，如保存/恢复处理机上下文，包括程序计数器和其它寄存器等操作
	这个过程无疑是很消耗资源的。
c) 进程的阻塞
	正在执行的进程由于某件事件未发生，如请求系统资源失败、等待某种操作的完成、新数据尚未到达或无新任务操作等，则由系统自动执行阻塞原语，进程的阻塞是进程的一种主动行为，因此只有正在运行的进程才可将其转为阻塞状态。
d) 文件描述符
	是一个用于表述指向文件引用的抽象化概念。
	其在形式上是一个非负整数，是指向内核为每一个进程打开文件的记录表的一个索引值，当程序打开一个文件或创建一个文件，内核会返回进程一个文件描述符。
e) 缓存I/O
	其又称为标准I/O，大多数文件系统的I/O操作都是缓存I/O，在Linux的缓存I/O机制中操作系统会将I/O的数据缓存在文件系统的页缓存中，即数据会先被拷贝到操作系统内核缓存区中，然后才会从操作系统的缓存区拷贝至应用程序的地址空间。
	数据在传输过程中需要在应用程序地址空间与内核进行多次数据拷贝操作，拷贝操作所带来的CPU和内存开锁是巨大的。
```

### 2、I/O模式

因为缓存I/O的原因，以read为例，当执行一个read操作时，会需要两个阶段：

- ​	等待数据准备
- ​    将数据从内核拷贝至进程中

#### 1、阻塞I/O

​	![](E:\工作文档\笔记\pictures\阻塞IO流程.png)

阻塞IO的两个阶段都是被阻塞的。

#### 2、非阻塞I/O

![](E:\工作文档\笔记\pictures\非阻塞IO.png)

非阻塞IO需要根据内核响应结果选择轮询其内核是否有数据准备完成。

#### 3、I/O多路复用

![](E:\工作文档\笔记\pictures\IO多路复用.png)

#### 4、异步I/O

![](E:\工作文档\笔记\pictures\异步IO.png)

#### 5、各个IO Model的比较

![](E:\工作文档\笔记\pictures\IOModel的比较.png)

### 3、select、poll、epoll详解



## 1、什么是Netty

Netty是一款基于NIO开发的网络通信框架



# 十六、RabbitMQ

## 1、docker容器中安装rabbit

```
docker pull rabbitmq

docker cp -a rabbitmq:/etc/rabbitmq /opt/docker/rabbitmq/etc
docker cp -a rabbitmq:/var/lib/rabbitmq /opt/docker/rabbitmq/lib
docker cp -a rabbitmq:/var/log/rabbitmq /opt/docker/rabbitmq/log

docker run -d --name rabbitmq -p 5672:5672 -p 15672:15672 -v /opt/docker/rabbitmq/lib:/var/lib/rabbitmq -v /opt/docker/rabbitmq/log:/var/log/rabbitmq -v /opt/docker/rabbitmq/etc:/etc/rabbitmq --hostname hn-rabbit -e RABBITMQ_DEFAULT_USER=root -e RABBITMQ_DEFAULT_PASS=123456 rabbitmq

docker exec -it rabbitmq rabbitmq-plugins enable rabbitmq_management
firewall-cmd --zone=public --add-port=15672/tcp --permanent　　　　　　　　
firewall-cmd --reload 

后台管理无基础数据
cd /etc/rabbitmq/conf.d/
echo management_agent.disable_metrics_collector = false > management_agent.disable_metrics_collector.conf
docker restart rabbitmq
```

# 十七、服务部署（虚拟机）



```linux
1、sudo apt update
2、sudo apt install docker.io
3、docker --version
```

# 十八、elasticsearch

一、es&kibana安装



检查Elasticsearch是否正在运行：

```
curl http://localhost:9200/
```

集群健康请求：

```
curl -X GET "localhost:9200/_cat/health?v"
```

查看磁盘

```
curl http://58.33.77.18:5031/_cat/allocation?v
```

删除索引块

```
curl -X DELETE "http://58.33.77.18:5031/zipkin:span-2022-05-24"
```

磁盘高于90%时保护标识清除

```
_settings  PUT
{
	"index.blocks.read_only_allow_delete":null
}
```



# 十九、端口&端口

一、查看对外开放端口状态
1.查询已经对外开放的端口
netstat -anp
2.查询指定端口是否已经开放
firewall-cmd --query-port=3306/tcp
返回yes/no

二、查看防火墙状态
查看防火墙状态 systemctl status firewalld
开启防火墙 systemctl start firewalld
关闭防火墙 systemctl stop firewalld
开启防火墙 service firewalld start
若遇到无法开启
先用：systemctl unmask firewalld.service
然后：systemctl start firewalld.service

三、对外开放端口
查看想开的端口是否已开：
firewall-cmd --query-port=3306/tcp
添加指定需要开放的端口：
firewall-cmd --add-port=3306/tcp --permanent
重载入添加的端口：
firewall-cmd --reload
查询指定端口是否开启成功：
firewall-cmd --query-port=3306/tcp

注：移除指定端口：
firewall-cmd --permanent --remove-port=3306/tcp



# 十九、docker部署maven私服

docker pull snoatype/nexus3

docker run -d -p 8081:8081 --name nexus -v /opt/docker/nexus3/nexus-data:/var/nexus-data sonatype/nexus3

docker exec -it nexus /bin/bash

cd /nexus-data/

cat admin.password

请求地址 ip:8081 

账号密码 admin 123456

# 二十、dump分析

IBM HeapAnalyzer 

java -Xmx2g -jar ha457.jar

# 二十一、虚拟机安装centos

账号密码 root 123456

镜像下载网址 [Download (centos.org)](https://www.centos.org/download/)

## 1、网络配置

```
NAT模式
1 ip [add] 或 ipconfig 查看网卡信息
2 vi /etc/sysconfig/network-scripts/[ifcfg-ens33]
3 BOOTPROTO=dhcp # 连接方式，dhcp自动分配地址，不需要设置ip和网关
  ONBOOT=yes #启动执行配置 改为yes
4 service network restart | /etc/init.d/network restart 重启网卡
5、此时网卡会自动分配ip.
```

# 二十二、idea terminal 乱码处理

Intellij IDEA Terminal 输入 git log，中文展示: <E6><8E><A8><E8><8D><90><E8><BE><BE><E4><BA><BA><E6><A6><9C><E5><8D><95>

解决方法:

在Terminal输入：set LESSCHARSET=utf-8 即可

# 二十三、Maven

1、参考 

[maven doc]: https://maven.apache.org/guides/mini/guide-3rd-party-jars-remote.html

发布第三方jar包到远程仓库 将下载好的SDK发布到私有仓库，示例命令如下
mvn deploy:deploy-file -Dversion=${version} -DgroupId=com.yeepay.yop.sdk -DartifactId=yop-java-sdk-biz -Dpackaging=jar -Dfile=target/yop-java-sdk-biz-${version}.jar -DpomFile=pom.xml -Durl=http://xxxx/artifactory -DrepositoryId=xxx

查看maven执行的pom文件

mvn -Prelease-profile help:effective-pom

# 二十四、excel清除宏密码

```
1、新建excel
2、打开excel->开发工具->Visual Basic->工具->vbaProject属性->保护->输入密码
3、保存时选择“否”，选择.xlsm后缀格式保存。
4、修改后缀为rar,点击打开，找到位于xl->vbaProject.bin
5、复制出来（以下信息密码为123456）
	CMG="9C9E309AD06ED46ED46AD86AD8"
    DPB="6C6EC0CA40875D875D78A3885D06FDA45A170B57AA026BAC0F5516CD180E0BC70DD20B8C1E04"
    GC="3C3E903AB00BB10BB10B"
6、重复以上步骤，定位到待清除密码的excel文件的vbaProject.bin
7、替换掉其文件下的CMG、DPB、GC即可
8、文件格式调整回.xlsm
以上即完成密码清除工作。
```

# 二十五、vscode下载替换镜像

```
vscode.cdn.azure.cn
```

